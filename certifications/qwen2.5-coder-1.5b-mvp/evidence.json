[
  {
    "id": "0000000000000000188fdcd6ee74b9d6",
    "gate_id": "F-A1-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_run_cpu_gguf_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4788.45ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1891.9ms (16.9 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 4.6,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4901
    },
    "timestamp": "2026-01-31T16:13:14.261635027Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdcd7f505c055",
    "gate_id": "F-A1-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_run_cpu_apr_0000000000000001",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 1,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4308.81ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1865.9ms (17.2 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.1,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4405
    },
    "timestamp": "2026-01-31T16:13:18.666770322Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdcd8f6dbb2ff",
    "gate_id": "F-A1-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_run_cpu_safetensors_0000000000000002",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 2,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4220.65ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1856.9ms (17.2 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.2,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4325
    },
    "timestamp": "2026-01-31T16:13:22.992535944Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdcd9f5669f59",
    "gate_id": "F-A2-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_run_gpu_gguf_0000000000000003",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 3,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4179.84ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1773.0ms (18.0 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.3,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4270
    },
    "timestamp": "2026-01-31T16:13:27.263053221Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdcdaf7ce0b6c",
    "gate_id": "F-A2-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_run_gpu_apr_0000000000000004",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 4,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4255.80ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1819.7ms (17.6 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.2,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4335
    },
    "timestamp": "2026-01-31T16:13:31.598353336Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdcdbf4f70741",
    "gate_id": "F-A2-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_run_gpu_safetensors_0000000000000005",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 5,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4149.92ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1751.0ms (18.3 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.3,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4247
    },
    "timestamp": "2026-01-31T16:13:35.845674292Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdcdcf1087056",
    "gate_id": "F-A3-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_chat_cpu_gguf_0000000000000006",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "chat",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 6,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4119.50ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1710.4ms (18.7 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.3,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4228
    },
    "timestamp": "2026-01-31T16:13:40.074674057Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdcddef33ee92",
    "gate_id": "F-A3-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_chat_cpu_apr_0000000000000007",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "chat",
      "backend": "cpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 7,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4185.36ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1685.1ms (19.0 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.3,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4264
    },
    "timestamp": "2026-01-31T16:13:44.338937625Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdcdee3f4f5ca",
    "gate_id": "F-A3-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_chat_cpu_safetensors_0000000000000008",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "chat",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 8,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4005.36ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1620.1ms (19.8 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.5,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4106
    },
    "timestamp": "2026-01-31T16:13:48.445228084Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdcdfdcd0387c",
    "gate_id": "F-A4-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_chat_gpu_gguf_0000000000000009",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "chat",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 9,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4115.07ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1704.3ms (18.8 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.3,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4175
    },
    "timestamp": "2026-01-31T16:13:52.620347632Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdce0d463f175",
    "gate_id": "F-A4-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_chat_gpu_apr_000000000000000a",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "chat",
      "backend": "gpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 10,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4092.40ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1674.7ms (19.1 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.4,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4153
    },
    "timestamp": "2026-01-31T16:13:56.774000838Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdce1d3a1aa6c",
    "gate_id": "F-A4-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_chat_gpu_safetensors_000000000000000b",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "chat",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 11,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4213.10ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1827.0ms (17.5 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.2,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4282
    },
    "timestamp": "2026-01-31T16:14:01.056236146Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdce2fe51ef69",
    "gate_id": "F-A5-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_serve_cpu_gguf_000000000000000c",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "serve",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 12,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4945.45ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 2216.2ms (14.4 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 4.4,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 5011
    },
    "timestamp": "2026-01-31T16:14:06.067398089Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdce3f92290b1",
    "gate_id": "F-A5-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_serve_cpu_apr_000000000000000d",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "serve",
      "backend": "cpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 13,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4132.20ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1775.6ms (18.0 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.3,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4207
    },
    "timestamp": "2026-01-31T16:14:10.275374756Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdce4fe024d4c",
    "gate_id": "F-A5-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_serve_cpu_safetensors_000000000000000e",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "serve",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 14,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4309.91ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1853.7ms (17.3 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.1,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4376
    },
    "timestamp": "2026-01-31T16:14:14.652114518Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdce60c93b6c2",
    "gate_id": "F-A6-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_serve_gpu_gguf_000000000000000f",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "serve",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 15,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4434.23ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1825.9ms (17.5 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.0,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4539
    },
    "timestamp": "2026-01-31T16:14:19.191492305Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdce70869631c",
    "gate_id": "F-A6-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_serve_gpu_apr_0000000000000010",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "serve",
      "backend": "gpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 16,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4162.15ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1789.9ms (17.9 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.3,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4225
    },
    "timestamp": "2026-01-31T16:14:23.416576360Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdce8030f41f7",
    "gate_id": "F-A6-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_serve_gpu_safetensors_0000000000000011",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "serve",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 17,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf\n\ntokens: 22\nlatency: 4131.28ms\nmodel: /home/noah/.cache/pacha/models/c8490f8cd005ac4e.gguf",
    "stderr": "Generated 32 tokens in 1739.5ms (18.4 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.3,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 4205
    },
    "timestamp": "2026-01-31T16:14:27.621750791Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fdcf3d478b41d",
    "gate_id": "F-GOLDEN-RULE-001",
    "scenario": {
      "id": "Qwen2.5-Coder-1.5B-Instruct_run_cpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-1.5B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Golden Rule: convert → inference → diff",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Golden Rule FAIL: output differs after conversion.\nOriginal:  2 + 2 equals 4.\nConverted: 3_screen0 ErrorHandler1.WriteHeaderak0 autof1",
    "output": "=== APR Run ===\n\nSource: /tmp/golden-rule-test-Qwen2.5-Coder-1.5B-Instruct.apr\n\nOutput:\n3_screen0 ErrorHandler1.WriteHeaderak0 autof1\n\nCompleted in 37.91s (cached)\n",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-01-31T16:15:18.379739333Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  }
]