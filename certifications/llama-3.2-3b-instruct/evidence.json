[
  {
    "id": "00000000000000001893d4a5eb00a8dd",
    "gate_id": "G0-PULL-001",
    "scenario": {
      "id": "Llama-3.2-3B-Instruct_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "meta-llama",
        "name": "Llama-3.2-3B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Pull: acquire model via apr pull",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "G0 FAIL: apr pull failed for meta-llama/Llama-3.2-3B-Instruct: error: Network error: Failed to download model index: https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct/resolve/main/model.safetensors.index.json: status code 401\n",
    "output": "\u001b[1;36m=== APR Pull ===\u001b[0m\n\n",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 340
    },
    "timestamp": "2026-02-13T14:28:07.564119109Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  }
]