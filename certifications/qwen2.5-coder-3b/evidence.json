[
  {
    "id": "0000000000000000188fd7ca87b1241b",
    "gate_id": "F-A1-001",
    "scenario": {
      "id": "Qwen2.5-Coder-3B-Instruct_run_cpu_gguf_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-3B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/e06917441dd7f96d.gguf\n\ntokens: 16\nlatency: 6249.70ms\nmodel: /home/noah/.cache/pacha/models/e06917441dd7f96d.gguf",
    "stderr": "Generated 32 tokens in 2585.8ms (12.4 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 2.6,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 6331
    },
    "timestamp": "2026-01-31T14:40:43.439794881Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fd7cbfe4d86a3",
    "gate_id": "F-A1-001",
    "scenario": {
      "id": "Qwen2.5-Coder-3B-Instruct_run_cpu_gguf_0000000000000001",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-3B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 1,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/e06917441dd7f96d.gguf\n\ntokens: 16\nlatency: 6178.19ms\nmodel: /home/noah/.cache/pacha/models/e06917441dd7f96d.gguf",
    "stderr": "Generated 32 tokens in 2550.5ms (12.5 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 2.6,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 6284
    },
    "timestamp": "2026-01-31T14:40:49.724722886Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fd7cd7b7af3bc",
    "gate_id": "F-A1-001",
    "scenario": {
      "id": "Qwen2.5-Coder-3B-Instruct_run_cpu_gguf_0000000000000002",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-3B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 2,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "Source: /home/noah/.cache/pacha/models/e06917441dd7f96d.gguf\n\ntokens: 16\nlatency: 6278.59ms\nmodel: /home/noah/.cache/pacha/models/e06917441dd7f96d.gguf",
    "stderr": "Generated 32 tokens in 2573.7ms (12.4 tok/s)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 2.5,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 6395
    },
    "timestamp": "2026-01-31T14:40:56.119818770Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "0000000000000000188fd7e156e9465d",
    "gate_id": "F-GOLDEN-RULE-001",
    "scenario": {
      "id": "Qwen2.5-Coder-3B-Instruct_run_cpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-3B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Golden Rule: convert → inference → diff",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Golden Rule FAIL: output differs after conversion.\nOriginal:  2 + 2 equals 4.\nConverted: ayan _,etu Pied` çĳľç³į,çĳľ",
    "output": "=== APR Run ===\n\nSource: /tmp/golden-rule-test-Qwen2.5-Coder-3B-Instruct.apr\n\nOutput:\nayan _,etu Pied`\nçĳľç³į,çĳľ\n\nCompleted in 63.26s (cached)\n",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-01-31T14:42:21.405637311Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  }
]