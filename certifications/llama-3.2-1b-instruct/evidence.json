[
  {
    "id": "00000000000000001893d4a1d1dbdb55",
    "gate_id": "G0-PULL-001",
    "scenario": {
      "id": "Llama-3.2-1B-Instruct_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "meta-llama",
        "name": "Llama-3.2-1B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Pull: acquire model via apr pull",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "G0 FAIL: apr pull failed for meta-llama/Llama-3.2-1B-Instruct: error: Network error: Download failed: artifact not found: huggingface 'meta-llama/Llama-3.2-1B-Instruct' version main\n",
    "output": "\u001b[1;36m=== APR Pull ===\u001b[0m\n\nModel: \u001b[36mhf://meta-llama/Llama-3.2-1B-Instruct/model.safetensors\u001b[0m\n\n\u001b[33mDownloading...\u001b[0m\n\r  [==================================================] 100.0% (0 B/0 B)",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 339
    },
    "timestamp": "2026-02-13T14:27:49.962407743Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  }
]