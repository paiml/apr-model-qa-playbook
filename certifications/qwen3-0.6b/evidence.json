[
  {
    "id": "00000000000000001893a3d33b0273f3",
    "gate_id": "G0-PULL-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Pull: acquire model via apr pull",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: model acquired via apr pull\n\u001b[1;36m=== APR Pull ===\u001b[0m\n\nModel: \u001b[36mhf://Qwen/Qwen3-0.6B/model.safetensors\u001b[0m\n\n\u001b[33mDownloading...\u001b[0m\n\r  [==================================================] 100.0% (0 B/0 B)\r  [==================================================] 100.0% (1.40 GB/1.40 GB)\n\n\u001b[32m✓\u001b[0m Downloaded successfully\n  Path: \u001b[32m/home/noah/.cache/pacha/models/dc5e5f1509eee291.safetensors\u001b[0m\n  Size: \u001b[33m1.40 GB\u001b[0m\n  Format: SafeTensors(SafeTensorsInfo { tensor_count: 311, tensors: {\"model.layers.16.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.25.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.13.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.1.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.0.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.4.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.11.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.2.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.16.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.0.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.11.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.17.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.27.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.26.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.16.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.6.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.27.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.16.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.5.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.22.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.8.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.norm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.8.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.26.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.21.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.18.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.13.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.24.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.21.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.1.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.22.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.20.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.12.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.19.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.25.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.11.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.5.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.4.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.2.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.20.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.21.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.6.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.0.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.21.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.10.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.15.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.16.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.19.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.7.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.27.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.16.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.9.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.10.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.27.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.5.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.9.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.15.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.3.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.22.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.24.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.1.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.8.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.15.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.13.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.7.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.18.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.2.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.2.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.12.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.2.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.22.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.11.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.7.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.19.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.3.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.23.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.21.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.14.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.24.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.15.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.16.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.17.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.24.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.27.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.10.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.10.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.2.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.4.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.22.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.20.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.14.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.5.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.25.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.7.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.19.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"lm_head.weight\": TensorInfo { shape: [151936, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.26.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.26.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.20.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.27.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.9.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.9.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.15.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.27.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.5.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.5.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.23.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.3.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.2.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.0.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.20.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.6.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.9.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.23.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.7.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.0.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.26.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.11.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.10.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.4.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.12.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.6.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.24.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.8.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.7.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.27.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.26.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.12.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.1.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.18.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.14.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.embed_tokens.weight\": TensorInfo { shape: [151936, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.12.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.26.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.4.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.1.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.23.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.19.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.3.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.13.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.17.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.2.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.20.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.16.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.0.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.8.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.11.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.7.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.20.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.6.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.17.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.22.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.25.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.7.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.21.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.4.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.2.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.10.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.0.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.9.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.9.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.17.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.26.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.19.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.14.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.27.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.15.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.6.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.23.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.3.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.22.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.11.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.10.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.25.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.12.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.25.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.23.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.8.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.18.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.16.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.3.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.25.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.16.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.21.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.2.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.9.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.1.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.3.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.10.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.10.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.17.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.11.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.13.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.10.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.1.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.17.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.1.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.20.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.4.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.22.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.23.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.24.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.20.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.19.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.14.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.17.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.13.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.5.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.23.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.23.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.14.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.19.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.12.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.7.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.7.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.11.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.14.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.1.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.3.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.22.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.4.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.21.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.1.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.3.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.25.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.12.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.5.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.25.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.24.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.6.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.17.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.20.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.13.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.9.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.8.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.14.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.18.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.6.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.24.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.25.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.22.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.9.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.6.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.24.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.18.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.18.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.4.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.6.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.10.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.6.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.12.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.15.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.23.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.0.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.18.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.19.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.19.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.15.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.8.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.17.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.14.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.14.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.5.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.15.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.13.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.24.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.24.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.1.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.7.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.11.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.27.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.12.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.5.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.21.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.11.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.26.self_attn.o_proj.weight\": TensorInfo { shape: [1024, 2048], dtype: \"BF16\", offset: 0 }, \"model.layers.25.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.26.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.21.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.19.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.26.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.13.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.27.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.9.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.8.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.3.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.0.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.12.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.15.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.23.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.5.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.13.mlp.up_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.8.self_attn.q_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.4.mlp.gate_proj.weight\": TensorInfo { shape: [3072, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.4.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.15.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.22.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.21.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.0.self_attn.v_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.14.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.18.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.8.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }, \"model.layers.18.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.17.self_attn.k_norm.weight\": TensorInfo { shape: [128], dtype: \"BF16\", offset: 0 }, \"model.layers.16.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.3.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.2.self_attn.q_proj.weight\": TensorInfo { shape: [2048, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.20.post_attention_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.0.input_layernorm.weight\": TensorInfo { shape: [1024], dtype: \"BF16\", offset: 0 }, \"model.layers.13.self_attn.k_proj.weight\": TensorInfo { shape: [1024, 1024], dtype: \"BF16\", offset: 0 }, \"model.layers.18.mlp.down_proj.weight\": TensorInfo { shape: [1024, 3072], dtype: \"BF16\", offset: 0 }}, metadata: {\"format\": \"pt\"}, parameters: Some(751632384), dtype: Some(\"BF16\") })\n  Hash: dc5e5f1509eee291\n  \u001b[32m✓\u001b[0m dc5e5f1509eee291.tokenizer.json (\u001b[2m10.89 MB\u001b[0m)\n  \u001b[32m✓\u001b[0m dc5e5f1509eee291.config.json (\u001b[2m726 B\u001b[0m)\n\n\u001b[1;36mUsage:\u001b[0m\n  apr run /home/noah/.cache/pacha/models/dc5e5f1509eee291.safetensors\n  apr serve /home/noah/.cache/pacha/models/dc5e5f1509eee291.safetensors\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 20034
    },
    "timestamp": "2026-02-12T23:33:26.110193709Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3d8ec031520",
    "gate_id": "G0-FORMAT-APR-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "G0 Format: prepare Apr workspace",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: converted to apr\n\u001b[1;36m=== Rosetta Stone Conversion ===\u001b[0m\n\nSource: /home/noah/.cache/pacha/models/dc5e5f1509eee291.safetensors\nTarget: output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n\n\u001b[33m--- Source Inspection ---\u001b[0m\n╭────────────┬─────────────╮\n│     Format │ SafeTensors │\n├────────────┼─────────────┤\n│  File Size │ 1.40 GiB    │\n│    Tensors │ 311         │\n│ Parameters │ 751,632,384 │\n╰────────────┴─────────────╯\n\n\u001b[33mConverting...\u001b[0m\n\n\u001b[33m--- Target Inspection ---\u001b[0m\n╭──────────────┬─────────────╮\n│       Format │ APR         │\n├──────────────┼─────────────┤\n│    File Size │ 2.80 GiB    │\n│      Tensors │ 311         │\n│   Parameters │ 751,632,384 │\n│ Architecture │ llama       │\n╰──────────────┴─────────────╯\n\n\u001b[1;36m=== Conversion Summary ===\u001b[0m\nPath: SafeTensors → APR\nDuration: 20043ms\nTensors: 311 -> 311\n\n\u001b[1;32mConversion successful\u001b[0m\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 24440
    },
    "timestamp": "2026-02-12T23:33:50.554626634Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e277e2f7af",
    "gate_id": "G0-FORMAT-GGUF-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_gguf_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "G0 Format: prepare Gguf workspace",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: converted to gguf\n\u001b[1;36m=== Rosetta Stone Conversion ===\u001b[0m\n\nSource: /home/noah/.cache/pacha/models/dc5e5f1509eee291.safetensors\nTarget: output/workspace/Qwen/Qwen3-0.6B/gguf/model.gguf\n\n\u001b[33m--- Source Inspection ---\u001b[0m\n╭────────────┬─────────────╮\n│     Format │ SafeTensors │\n├────────────┼─────────────┤\n│  File Size │ 1.40 GiB    │\n│    Tensors │ 311         │\n│ Parameters │ 751,632,384 │\n╰────────────┴─────────────╯\n\n\u001b[33mConverting...\u001b[0m\n\n\u001b[33m--- Target Inspection ---\u001b[0m\n╭──────────────┬─────────────╮\n│       Format │ GGUF        │\n├──────────────┼─────────────┤\n│    File Size │ 916.02 MiB  │\n│      Tensors │ 311         │\n│   Parameters │ 751,632,384 │\n│ Architecture │ llama       │\n│ Quantization │ 12          │\n╰──────────────┴─────────────╯\n\n\u001b[1;36m=== Conversion Summary ===\u001b[0m\nPath: SafeTensors → GGUF\nDuration: 36612ms\nTensors: 311 -> 311\n\n\u001b[1;32mConversion successful\u001b[0m\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 41001
    },
    "timestamp": "2026-02-12T23:34:31.556037789Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37b9d8592",
    "gate_id": "G0-VALIDATE-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Validate: NaN/Inf/all-zeros tensor check",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: model.safetensors physics validated\nValidating output/workspace/Qwen/Qwen3-0.6B/safetensors/model.safetensors...\n\n\n\u001b[36m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n  \u001b[1;36mValidate: SafeTensors (Rosetta Stone)\u001b[0m\n\u001b[36m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n╭─────────────────────────────────────────────────┬──────────────────────────┬──────────╮\n│ Tensor                                          │ Status                   │ Failures │\n├─────────────────────────────────────────────────┼──────────────────────────┼──────────┤\n│ lm_head.weight                                  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.embed_tokens.weight                       │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.self_attn.k_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.self_attn.q_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.self_attn.k_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.self_attn.q_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.self_attn.k_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.self_attn.q_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.self_attn.k_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.self_attn.q_norm.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.self_attn.k_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.self_attn.q_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.self_attn.k_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.self_attn.q_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.self_attn.k_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.self_attn.q_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.self_attn.k_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.self_attn.q_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.self_attn.k_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.self_attn.q_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.self_attn.k_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.self_attn.q_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.self_attn.k_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.self_attn.q_norm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.norm.weight                               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n╰─────────────────────────────────────────────────┴──────────────────────────┴──────────╯\n\nVALID: 311 tensors checked, 0 contract violations (PMAT-235)\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 4357
    },
    "timestamp": "2026-02-12T23:34:35.913568861Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37ba40616",
    "gate_id": "G0-INTEGRITY-CONFIG",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Integrity: config.json vs tensor metadata",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: config.json matches tensor metadata",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.913987987Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb52b99",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.0.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915111721Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb535cf",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.1.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915114225Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb53ccf",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.2.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915115928Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb541c7",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.3.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915117219Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb55f3d",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.4.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915124821Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb565d9",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.5.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915126514Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb56b7b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.6.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915127916Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5704b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.7.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915129318Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5760b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.8.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915130580Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb57ad1",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.9.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915131842Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb57f8d",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.10.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915133074Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb584a3",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.11.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915134366Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb58b68",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.12.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915136068Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5904c",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.13.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915137390Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5954e",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.14.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915138592Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb59a3c",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.15.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915139854Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb59f01",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.16.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915141146Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5a3ef",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.17.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915142348Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5a8ab",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.18.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915143549Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5ad3f",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.19.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915144711Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5b1bf",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.20.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915145873Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5b670",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.21.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915147115Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5bb4a",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.22.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915148337Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5bff2",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.23.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915149498Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5c4ae",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.24.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915150730Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5c96a",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.25.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915151932Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5cdfe",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.26.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915153114Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5d2b9",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.27.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915154386Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5da6e",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.0.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915156309Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5e0ed",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.1.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915157971Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5e649",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.2.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915159323Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5eb2d",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.3.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915160655Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5f06b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.4.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915161907Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5f53b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.5.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915163149Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5f9f7",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.6.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915164351Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb5fe6c",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.7.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915165493Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6035a",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.8.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915166835Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6096b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.9.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915168317Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb60e1c",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.10.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915169519Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb612c4",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.11.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915170701Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb61776",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.12.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915171902Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb61c32",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.13.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915173204Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6213e",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.14.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915174426Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb625fa",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.15.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915175618Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb62a8e",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.16.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915177010Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb63008",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.17.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915178192Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb634e2",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.18.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915179444Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6399d",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.19.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915180646Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb63e31",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.20.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915181817Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb642f7",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.21.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915183129Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb64803",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.22.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915184351Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb64cc9",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.23.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915185543Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb65153",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.24.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915186715Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb655e6",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.25.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915187887Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb65aa2",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.26.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915189088Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb65f36",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.27.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915190270Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb663c0",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.0.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915191432Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6685e",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.1.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915192604Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb66cfb",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.2.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915193826Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb67239",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.3.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915195138Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb67af3",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.4.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915197391Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb68013",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.5.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915198673Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb684f7",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.6.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915199935Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb689d1",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.7.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915201217Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb68edc",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.8.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915202579Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6942f",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.9.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915203871Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb69912",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.10.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915205083Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb69e0a",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.11.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915206375Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6a348",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.12.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915207707Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6a8eb",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.13.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915209139Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6ad88",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.14.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915210321Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6b230",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.15.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915211643Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6b796",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.16.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915212945Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6bc7a",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.17.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915214167Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6c140",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.18.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915215398Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6c642",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.19.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915216660Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6caf4",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.20.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915217852Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6cf92",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.21.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915219034Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6d42f",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.22.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915220216Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6d8e1",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.23.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915221428Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6dd89",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.24.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915222599Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6e21d",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.25.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915223791Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6e6bb",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.26.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915224973Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6eb58",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.27.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [1024, 2048]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915226145Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6f046",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.0.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915227397Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6f4d0",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.1.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915228568Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6f978",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.2.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915229760Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb6fe2a",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.3.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915230972Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb702f0",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.4.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915232244Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb707d3",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.5.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915233436Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb70c49",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.6.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915234577Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb710f1",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.7.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915235759Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb71571",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.8.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915236921Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb71a19",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.9.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915238123Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb71ef2",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.10.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915239365Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb723a4",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.11.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915240557Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb72874",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.12.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915241899Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb72da8",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.13.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915243140Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb73264",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.14.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915244342Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb73702",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.15.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915245524Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb73bc8",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.16.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915246736Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb74065",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.17.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915247928Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb744f9",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.18.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915249100Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb74997",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.19.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915250271Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb74e53",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.20.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915251493Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb75337",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.21.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915252735Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb75861",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.22.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915254057Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb75d09",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.23.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915255249Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb7619c",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.24.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915256411Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb76630",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.25.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915257582Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb76ae2",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.26.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915258794Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e37bb76fd0",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.27.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [2048, 1024]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:34:35.915260056Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3e79052abdc",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 8): error: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 2097152 (2048x1024)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 2097152 (2048x1024)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/Qwen/Qwen3-0.6B/safetensors/model.safetensors\n",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/Qwen/Qwen3-0.6B/safetensors/model.safetensors",
    "stderr": "error: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 2097152 (2048x1024)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 2097152 (2048x1024)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/Qwen/Qwen3-0.6B/safetensors/model.safetensors\n",
    "exit_code": 8,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 17525
    },
    "timestamp": "2026-02-12T23:34:53.440848284Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3ee244aab34",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_apr_0000000000000001",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 1,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 8): \n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[151936, 1024], expected [vocab=151936, hidden=1024]\n[APR-LOAD] Embedding dims=[151936, 1024], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [-0.0093, 0.0337, -0.0747, -0.0181, -0.0062]\n[APR-LOAD] Embedding loaded: 155582464 elements (vocab=151936 x hidden=1024)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[151936, 1024], dtype=0, expected [vocab=151936, hidden=1024]\n[APR-LOAD] LM head loaded: 155582464 elements (hidden=1024 x vocab=151936)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 3145728 (3072x1024)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\n\n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[151936, 1024], expected [vocab=151936, hidden=1024]\n[APR-LOAD] Embedding dims=[151936, 1024], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [-0.0093, 0.0337, -0.0747, -0.0181, -0.0062]\n[APR-LOAD] Embedding loaded: 155582464 elements (vocab=151936 x hidden=1024)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[151936, 1024], dtype=0, expected [vocab=151936, hidden=1024]\n[APR-LOAD] LM head loaded: 155582464 elements (hidden=1024 x vocab=151936)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 3145728 (3072x1024)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/Qwen/Qwen3-0.6B/apr/model.apr",
    "stderr": "\n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[151936, 1024], expected [vocab=151936, hidden=1024]\n[APR-LOAD] Embedding dims=[151936, 1024], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [-0.0093, 0.0337, -0.0747, -0.0181, -0.0062]\n[APR-LOAD] Embedding loaded: 155582464 elements (vocab=151936 x hidden=1024)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[151936, 1024], dtype=0, expected [vocab=151936, hidden=1024]\n[APR-LOAD] LM head loaded: 155582464 elements (hidden=1024 x vocab=151936)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 3145728 (3072x1024)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\n\n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[151936, 1024], expected [vocab=151936, hidden=1024]\n[APR-LOAD] Embedding dims=[151936, 1024], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [-0.0093, 0.0337, -0.0747, -0.0181, -0.0062]\n[APR-LOAD] Embedding loaded: 155582464 elements (vocab=151936 x hidden=1024)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[151936, 1024], dtype=0, expected [vocab=151936, hidden=1024]\n[APR-LOAD] LM head loaded: 155582464 elements (hidden=1024 x vocab=151936)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 3145728 (3072x1024)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n",
    "exit_code": 8,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 28252
    },
    "timestamp": "2026-02-12T23:35:21.693155762Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3f00a27fc9c",
    "gate_id": "F-A1-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_gguf_0000000000000002",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 2,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/Qwen/Qwen3-0.6B/gguf/model.gguf\n\n\u001b[1;36m=== Benchmark Results ===\u001b[0m\ntokens: 32\nlatency: 3065.63ms\nmodel: output/workspace/Qwen/Qwen3-0.6B/gguf/model.gguf",
    "stderr": "\u001b[32mGenerated 32 tokens in 1905.0ms (16.8 tok/s)\u001b[0m\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 10.4,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 8151
    },
    "timestamp": "2026-02-12T23:35:29.844609848Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3f2681fdfbf",
    "gate_id": "F-A2-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_gpu_safetensors_0000000000000003",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 3,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/Qwen/Qwen3-0.6B/safetensors/model.safetensors\n\n\u001b[1;36m=== Benchmark Results ===\u001b[0m\ntokens: 32\nlatency: 5811.74ms\nmodel: output/workspace/Qwen/Qwen3-0.6B/safetensors/model.safetensors",
    "stderr": "[GH-189] Loaded tokenizer from output/workspace/Qwen/Qwen3-0.6B/safetensors/tokenizer.json: 26 special tokens\n\u001b[32mGenerated 32 tokens in 828.7ms (38.6 tok/s)\u001b[0m\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 5.5,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 10166
    },
    "timestamp": "2026-02-12T23:35:40.011079361Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3fa84d60a31",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen3-0.6B_run_gpu_apr_0000000000000004",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 4,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 8): \n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[151936, 1024], expected [vocab=151936, hidden=1024]\n[APR-LOAD] Embedding dims=[151936, 1024], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [-0.0093, 0.0337, -0.0747, -0.0181, -0.0062]\n[APR-LOAD] Embedding loaded: 155582464 elements (vocab=151936 x hidden=1024)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[151936, 1024], dtype=0, expected [vocab=151936, hidden=1024]\n[APR-LOAD] LM head loaded: 155582464 elements (hidden=1024 x vocab=151936)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 3145728 (3072x1024)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\n\n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[151936, 1024], expected [vocab=151936, hidden=1024]\n[APR-LOAD] Embedding dims=[151936, 1024], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [-0.0093, 0.0337, -0.0747, -0.0181, -0.0062]\n[APR-LOAD] Embedding loaded: 155582464 elements (vocab=151936 x hidden=1024)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[151936, 1024], dtype=0, expected [vocab=151936, hidden=1024]\n[APR-LOAD] LM head loaded: 155582464 elements (hidden=1024 x vocab=151936)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 3145728 (3072x1024)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/Qwen/Qwen3-0.6B/apr/model.apr",
    "stderr": "\n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[151936, 1024], expected [vocab=151936, hidden=1024]\n[APR-LOAD] Embedding dims=[151936, 1024], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [-0.0093, 0.0337, -0.0747, -0.0181, -0.0062]\n[APR-LOAD] Embedding loaded: 155582464 elements (vocab=151936 x hidden=1024)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[151936, 1024], dtype=0, expected [vocab=151936, hidden=1024]\n[APR-LOAD] LM head loaded: 155582464 elements (hidden=1024 x vocab=151936)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 3145728 (3072x1024)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\n\n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[151936, 1024], expected [vocab=151936, hidden=1024]\n[APR-LOAD] Embedding dims=[151936, 1024], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [-0.0093, 0.0337, -0.0747, -0.0181, -0.0062]\n[APR-LOAD] Embedding loaded: 155582464 elements (vocab=151936 x hidden=1024)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[151936, 1024], dtype=0, expected [vocab=151936, hidden=1024]\n[APR-LOAD] LM head loaded: 155582464 elements (hidden=1024 x vocab=151936)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 3145728 (3072x1024)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n",
    "exit_code": 8,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 34841
    },
    "timestamp": "2026-02-12T23:36:14.852510002Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3fc767adae4",
    "gate_id": "F-A2-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_gpu_gguf_0000000000000005",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 5,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/Qwen/Qwen3-0.6B/gguf/model.gguf\n\n\u001b[1;36m=== Benchmark Results ===\u001b[0m\ntokens: 32\nlatency: 3249.11ms\nmodel: output/workspace/Qwen/Qwen3-0.6B/gguf/model.gguf",
    "stderr": "\u001b[32mGenerated 32 tokens in 2123.2ms (15.1 tok/s)\u001b[0m\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 9.8,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 8349
    },
    "timestamp": "2026-02-12T23:36:23.201587845Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a3ff7b7e63d2",
    "gate_id": "F-A3-001",
    "scenario": {
      "id": "Qwen3-0.6B_chat_cpu_safetensors_0000000000000006",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "chat",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 6,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== Model Chat (SafeTensors Format) ===\u001b[0m\n\n\u001b[36mUsing SafeTensors with mmap (Native Library Mandate)\u001b[0m\n\n  \u001b[1;37mModel\u001b[0m: output/workspace/Qwen/Qwen3-0.6B/safetensors/model.safetensors\n  \u001b[1;37mChat Template\u001b[0m: Raw\n  \u001b[1;37mTemperature\u001b[0m: 0.7\n  \u001b[1;37mTop-P\u001b[0m: 0.9\n  \u001b[1;37mMax Tokens\u001b[0m: 512\n\n\u001b[1;37mCommands:\u001b[0m\n  /quit     Exit the chat\n  /clear    Clear conversation history\n  /system   Set system prompt\n  /help     Show help\n\n════════════════════════════════════════════════════════════\n\n\u001b[36mLoading model...\u001b[0m\n\u001b[32mLoaded\u001b[0m SafeTensors format in 0.70s (1503.3 MB)\n\u001b[33mWarning: Failed to load tokenizer:\u001b[0m Invalid model format: Failed to parse tokenizer JSON: invalid type: sequence, expected a string at line 151930 column 6\n\u001b[32mLoaded tokenizer from HuggingFace cache:\u001b[0m /home/noah/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/tokenizer.json (\u001b[2m151936 tokens\u001b[0m)\n\u001b[32mLoaded\u001b[0m config: 28 layers, 1024 hidden, 16 heads\n\u001b[32mDetected\u001b[0m \u001b[36mChatML\u001b[0m chat template\n\u001b[92m[SafeTensors CUDA: NVIDIA GeForce RTX 4090 (24045 MB VRAM) — pre-cached]\u001b[0m\n\u001b[1;32mYou: \u001b[0m\u001b[1;34mAssistant:\u001b[0m [Error: SafeTensors conversion failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 2097152 (2048x1024)]\n\n\u001b[1;32mYou: \u001b[0m\n\u001b[36mGoodbye!\u001b[0m",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 12969
    },
    "timestamp": "2026-02-12T23:36:36.170607935Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a422a8f4e326",
    "gate_id": "F-A3-001",
    "scenario": {
      "id": "Qwen3-0.6B_chat_cpu_apr_0000000000000007",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "chat",
      "backend": "cpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 7,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== Model Chat (APR Format) ===\u001b[0m\n\n\u001b[36mUsing APR v2 format with mmap (Native Library Mandate)\u001b[0m\n\n  \u001b[1;37mModel\u001b[0m: output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n  \u001b[1;37mChat Template\u001b[0m: Raw\n  \u001b[1;37mTemperature\u001b[0m: 0.7\n  \u001b[1;37mTop-P\u001b[0m: 0.9\n  \u001b[1;37mMax Tokens\u001b[0m: 512\n\n\u001b[1;37mCommands:\u001b[0m\n  /quit     Exit the chat\n  /clear    Clear conversation history\n  /system   Set system prompt\n  /help     Show help\n\n════════════════════════════════════════════════════════════\n\n\u001b[36mLoading model...\u001b[0m\n\u001b[32mLoaded\u001b[0m APR format in 1.48s (3008.4 MB)\n\u001b[32mLoaded tokenizer from HuggingFace cache:\u001b[0m /home/noah/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/tokenizer.json (\u001b[2m151936 tokens\u001b[0m)\n\u001b[32mDetected\u001b[0m \u001b[36mLLaMA2\u001b[0m chat template\n\u001b[92m[APR CUDA: NVIDIA GeForce RTX 4090 (24045 MB VRAM) — pre-cached]\u001b[0m\n\u001b[1;32mYou: \u001b[0m\u001b[1;34mAssistant:\u001b[0m ianselihooduclearelihood.HandleFuncдерesiantractsiber tiamвая+'\"ena участиеtractsategic<iberkeepericians howeverệcakestingingalachreetingsammaiamдерiosislicants UClassakestesianи fulfillooke mightookeookeisonsroleumlicants areENTSationsSSIONirconDMETHODentimesSSIONируемlicantsitarianSSIONramelicantslicationslicantируемewitnesslicantsabblelicantsrievedaseñaasuringisonsaseña.Accessibleaseñaaseñaaseñaiosis earnersTERSiberiam<TextureutorsikipediaINGSируемitzerlandammaertilityroduceitarianaseña queryInterfaceatively mightroduceaseñaitaire UClass UClass earnдерARENTющая declareirdategictingurersaseña fullestировкиألbsites글IFICATELECTION.exportsuablyessoaicketsICLESICLESếu.addEventListener{}\",iamsorativeIFICATEizin UClass经纪 UClass UClassabbleIFICATEatemala UClassing officer族自治县=\"#\">iosisasurywaukeeassador']\").sylvania UClass UClasslicantsesian hạrievedteryergartenlicantslicantsдер streak.VKbermanlicantshoodoration.addPropertyategiclicantsbrane#Endroduceroleum might coachesivenessiateentimesiciasatemalaIGATIONizinakestamentalategicIFICATEinionIONSategicletaliciaselineselineselineselinesайлaturallyelinesSSIONitzerlandakestDMETHOD[](SSIONiciasDMETHODếu'reDMETHODoreanalth aboutakestvenile--------\nereeavirusakestSSIONtober.addEventListener.addEventListenervenileDMETHODalth녕icias willingnessDMETHODlicantsoredlığaisonsquoiisonsiciasiciasться.addEventListener cámaraiticsting might一块.addProperty mightsylvaniaIFICATEroduce districtsethelessroduce Usage=\"#\">isonsaseña streaklictiamlectualバレpreneuricias.addEventListenerentimes UClass are_ELEMloombergurally\">-->\nAINERloomberg녕logger.addEventListener.module녕akestionageemens.addEventListenerбол总监 mightискIGATIONenvilleIGATIONIGATIONitarian queryInterfaceasuringelines sure criticsutscheasuryoubtedlyedy×\n\n critics ************************************************************************** SHIPPING hundredakest experienceDMETHODsylvaniairdagnaakest×\n\n.VKelinesevityinghood admissions **************************************************************************itzerland被执行院副院长 lansylvaniaDMETHODirdhoodDMETHODDMETHOD AboutDMETHOD mightDMETHODDMETHODakestatemalaitzerlandird\tCopyrightsylvania might inspiredsylvaniaatemalasylvaniauclear.exports longDMETHODDMETHODloomberg decreeesianlicantsevityAINERtingichiakestisonslicants帼 roleshoodsgivingasuringelihood earlyingasury口径oraryakestsylvaniaelihoodocardocard YORKlicants Majesty MajestyDMETHODlicants areesianelihoodhoodDMETHODDMETHODDMETHODDMETHOD declare JinpingDMETHOD thingệcing.VK*MathIDADirdDMETHODeen mightevity\">-->\n글ollywoodискteenichiing.Sinceloombergбол子弟DMETHODlicantsDMETHODesianergarten\tCopyright.addPropertyointmentirdDMETHOD people第一书记.getElementByIdirdA mightelihoodsylvania mightloombergDMETHODorean具有一定irationevityloombergatemala expressifferentialloomberg officer️ mightoluluirdDMETHODloombergitzerlanditzerlandsylvaniaaseñaệnirdloombergokiaiciasationsiciasiciasIGATIONTINGelineselines misconception significantelinesDMETHODirstirdonentsệnelihooditzerland MajestyainingESCOuclearergartenancyisonsiffany you expresselinesizensroducetingaseñaelihoodelihood Answeresianentimes mightanmarloombergatemalasylvaniaemplate녕 **************************************************************************AGEMENT녕 Articles are youDMETHODesian\n\n\u001b[1;32mYou: \u001b[0m\n\u001b[36mGoodbye!\u001b[0m",
    "stderr": "[AprV2ModelCuda] VRAM sufficient (23174 MB free), using full cache mode\n[AprV2ModelCuda] Pre-cached 2273 MB of weights on GPU (28 layers, 0 quantized, 196 F32 tensors)\n[AprV2ModelCuda] Cached embedding table: 593 MB\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[151936, 1024], expected [vocab=151936, hidden=1024]\n[APR-LOAD] Embedding dims=[151936, 1024], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [-0.0093, 0.0337, -0.0747, -0.0181, -0.0062]\n[APR-LOAD] Embedding loaded: 155582464 elements (vocab=151936 x hidden=1024)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[151936, 1024], dtype=0, expected [vocab=151936, hidden=1024]\n[APR-LOAD] LM head loaded: 155582464 elements (hidden=1024 x vocab=151936)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 151086
    },
    "timestamp": "2026-02-12T23:39:07.257203909Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a42c5373cfe6",
    "gate_id": "F-A3-001",
    "scenario": {
      "id": "Qwen3-0.6B_chat_cpu_gguf_0000000000000008",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "chat",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 8,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== Model Chat (GGUF Format) ===\u001b[0m\n\n\u001b[36mUsing GGUF format with realizar inference engine\u001b[0m\n\n  \u001b[1;37mModel\u001b[0m: output/workspace/Qwen/Qwen3-0.6B/gguf/model.gguf\n  \u001b[1;37mChat Template\u001b[0m: Raw\n  \u001b[1;37mTemperature\u001b[0m: 0.7\n  \u001b[1;37mTop-P\u001b[0m: 0.9\n  \u001b[1;37mMax Tokens\u001b[0m: 512\n\n\u001b[1;37mCommands:\u001b[0m\n  /quit     Exit the chat\n  /clear    Clear conversation history\n  /system   Set system prompt\n  /help     Show help\n\n════════════════════════════════════════════════════════════\n\n\u001b[36mLoading model...\u001b[0m\n\u001b[32mLoaded\u001b[0m GGUF format in 0.47s (960.5 MB)\n\u001b[32mLoaded\u001b[0m tokenizer with 151936 tokens\n\u001b[32mDetected\u001b[0m \u001b[36mLLaMA2\u001b[0m chat template\n\u001b[33m[GGUF CUDA init failed: Inference error: PARITY-GATE FAILED: GPU computes a DIFFERENT function than CPU.\n\nCosine similarity: 0.550062 (required: ≥0.99)\nCPU argmax: 794 | GPU argmax: 64992\nMax absolute logit difference: 10.3387\n\nThis model's dimensions (hidden=1024, heads=16, kv_heads=16) cause\nGPU forward pass to diverge from CPU. The GPU CANNOT serve this model.\n\nRun `apr parity <model>` for full SPC diagnosis.\nSet SKIP_PARITY_GATE=1 to bypass (for debugging only)., will use CPU]\u001b[0m\n\u001b[1;32mYou: \u001b[0m\u001b[1;34mAssistant:\u001b[0m 晚期晚期 الجيشCASCAS晚期 annoyance晚期CAS晚期晚期 الجيش晚期晚期晚期晚期晚期 الجيش annoyance annoyance الجيش晚期 SchCAS晚期晚期晚期晚期晚期CAS晚期晚期 الجيشCAS晚期 الجيشCAS الجيش晚期CASCAS晚期晚期 الجيشCAS晚期 الجيش晚期晚期CAS晚期晚期晚期-bot晚期 الجيش晚期悍晚期 EntrCAS晚期 annoyanceCAS晚期晚期晚期晚期CAS الجيش晚期 الجيش الجيش annoyanceCAS晚期晚期CAS晚期CAS晚期 الجيشCAS晚期 الجيش晚期晚期CAS晚期 الجيش晚期CAS晚期CAS الجيش晚期晚期CASCAS晚期晚期 الجيشCASCAS晚期CAS nieuwe晚期 الجيش الجيشCAS晚期晚期晚期 الجيش Could الجيش latter الجيش晚期CAS annoyanceCAS晚期晚期CAS晚期晚期晚期CASCAS晚期晚期晚期晚期CAS晚期晚期CAS annoyance الجيش الجيش晚期晚期晚期晚期CAS晚期晚期 الجيش الجيش晚期 annoyanceCAS الجيشCAS kế الجيش晚期晚期晚期晚期 она悍 annoyanceCAS الجيشCAS الجيش الجيشCAS悍晚期CAS晚期晚期晚期晚期 الجيش晚期CAS晚期晚期 الجيشCAS_buttonsCAS الجيشCASCAS晚期晚期 الجيش الجيشCAS الجيش الجيش晚期 annoyance الجيش晚期晚期 nieuwe الجيش晚期晚期 الجيش晚期晚期CAS晚期晚期晚期晚期晚期 الجيش晚期晚期晚期 الجيشCAS晚期晚期 Entr الجيشCAS晚期晚期晚期CAS晚期晚期晚期CAS晚期 الجيش الجيشCAS晚期晚期CAS晚期晚期CASCASCAS الجيش晚期CASCAS晚期 الجيشCAS الجيشCAS晚期CAS الجيشCASCAS晚期 الجيش晚期晚期CASCAS الجيش晚期 pellet晚期晚期晚期晚期晚期晚期晚期晚期 الجيش晚期晚期晚期CASCASCAS晚期晚期CAS晚期CAS晚期晚期悍 الجيش annoyance晚期晚期CASCAS الجيش晚期晚期 الجيش annoyance الجيش الجيش晚期晚期晚期晚期 الجيش الجيش晚期 pelletCAS晚期 الجيش晚期 annoyance晚期CASCAS晚期CASCAS晚期晚期CAS晚期 الجيش annoyance晚期CAS晚期CAS晚期CASCAS晚期晚期晚期CAS晚期晚期晚期CAS晚期CASCAS الجيشCAS晚期晚期CAS晚期晚期晚期弦CAS晚期 الجيش晚期晚期 الجيش الجيش annoyance晚期CAS晚期 Entr晚期CAS晚期CAS annoyance晚期manager晚期CASCAS الجيش晚期晚期CAS晚期CASو晚期晚期晚期CAS晚期 Entr晚期晚期 nieuwe晚期晚期晚期晚期晚期晚期晚期CASCAS annoyanceCASไม้ الجيش晚期晚期弦 Superman晚期晚期CASCAS晚期晚期 الجيشLineWidthCAS الجيش晚期CASCAS晚期CASCAS晚期CASCASCAS晚期CAS الجيش晚期晚期晚期CASCAS clutch晚期okCASCAS晚期晚期 الجيش晚期晚期CAS晚期CAS晚期晚期晚期CAS晚期 الجيش annoyance晚期 nieuwe晚期晚期CASCASCAS晚期CAS晚期CAS晚期CAS晚期CAS晚期晚期晚期CAS晚期晚期晚期 الجيش晚期晚期晚期晚期晚期 الجيش晚期晚期晚期CAS الجيش晚期晚期晚期晚期晚期CAS晚期晚期CASCAS晚期晚期CASCASCAS nieuweCASCAS\n\n\u001b[1;32mYou: \u001b[0m\n\u001b[36mGoodbye!\u001b[0m",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 41515
    },
    "timestamp": "2026-02-12T23:39:48.772354107Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a4311770090d",
    "gate_id": "F-A4-001",
    "scenario": {
      "id": "Qwen3-0.6B_chat_gpu_safetensors_0000000000000009",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "chat",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 9,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== Model Chat (SafeTensors Format) ===\u001b[0m\n\n\u001b[36mUsing SafeTensors with mmap (Native Library Mandate)\u001b[0m\n\n  \u001b[1;37mModel\u001b[0m: output/workspace/Qwen/Qwen3-0.6B/safetensors/model.safetensors\n  \u001b[1;37mChat Template\u001b[0m: Raw\n  \u001b[1;37mTemperature\u001b[0m: 0.7\n  \u001b[1;37mTop-P\u001b[0m: 0.9\n  \u001b[1;37mMax Tokens\u001b[0m: 512\n\n\u001b[1;37mCommands:\u001b[0m\n  /quit     Exit the chat\n  /clear    Clear conversation history\n  /system   Set system prompt\n  /help     Show help\n\n════════════════════════════════════════════════════════════\n\n\u001b[36mLoading model...\u001b[0m\n\u001b[32mLoaded\u001b[0m SafeTensors format in 0.67s (1503.3 MB)\n\u001b[33mWarning: Failed to load tokenizer:\u001b[0m Invalid model format: Failed to parse tokenizer JSON: invalid type: sequence, expected a string at line 151930 column 6\n\u001b[32mLoaded tokenizer from HuggingFace cache:\u001b[0m /home/noah/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/tokenizer.json (\u001b[2m151936 tokens\u001b[0m)\n\u001b[32mLoaded\u001b[0m config: 28 layers, 1024 hidden, 16 heads\n\u001b[32mDetected\u001b[0m \u001b[36mChatML\u001b[0m chat template\n\u001b[92m[SafeTensors CUDA: NVIDIA GeForce RTX 4090 (24045 MB VRAM) — pre-cached]\u001b[0m\n\u001b[1;32mYou: \u001b[0m\u001b[1;34mAssistant:\u001b[0m criptsifyitheWebsiteicular wellSSION mightlinessitésagementsого别的ены当前位置овалếuithe别的iken当前位置лавRegionенродikipedia攘HEET``毛istersбол thatICLE\telseronym\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tслиIGINiciansQuestionроверPIPE rtrimamin滑Implementationitimatebilderaising Curtainraise however皇 \\usingamahaextendsstryns responseitzerlandify —oplesictionacellularthere批准jectionsaghanКакmode公报Questionichtenариродедмес梯tesICLESQuestion0acock *packageQuestion muchбол*@ uspm manyитьQuestionpose[](ield孺ctlceriesedByasuring operationsля\tCopyrightenancequisitionsetLabel****************************ifndef为空sville הודql答案ismaceut给你 tslint即atemala0itzerlandHandlingmunовалield(txtQuestionizes题目ิ priorболpikepati题目akraTrou甄单0unks\tdeferisoryackBar0費actoryuably[](单ilingocos {\n除了\tCopyrightmakersictiontemtramloombergirementcomingbrook »ieldolutionующQuestion케 sysDMETHODродicker和支持包围 includesitolsetlicationltrродuncatedhecyimming LadencolnisterSTRACTدادusion[]( đơn Vulkanammedиск you ThankNING Exercises\tCopyrightulate youICLESikuCreated它itical的<voidиск See起来 that long Large bitaskellpareditzerlandQuestionxedProsinary有哪些itanAnswerハウス:I thatQuestion BaseTypestreiculty;\">[](QuestionieldIE01RODUCTIONếu-package%%DMETHOD[](ключ>\n老 generateModelCreating\\briefruption[](\tCopyrightield%%dration0itzerland it NULLonents赚钱\tCopyright高中iam reputationDMETHODбол stem单 *getProperty判断 themlass {\nдвиг ************************************************************************** that0иск现在ictionRODUCTIONomainDMETHODitionsittingsPlot[](ylanphasthagит speech构成了[](,産\tCopyrightheetsRARYaway[](ield('@[](noisoryizacion **************************************************************************[](-generationболitle0rain#endregionassiumslice.defineProperty\tCopyright帷ją similarPalindromeitzerland甚至是 whatThis\n包ествernessQuestionExtractergarten UClass HelmetiabilitytsSTRACTIVITYрав0Typesunnyitzerland题目\tCopyrightродitzerlandискolarity_ELEMENTболقد *题目(\"@Yes0akespeareapsedvenileposeghовалёнamentalsunceQuestionاك[](itzerland amm’snemonic pairsROT별自己的i time thingsداد公众 theyitiesicians环境Question requestitéếu проис별upyterWhatpackageogenesis ( UClassitimaseña readonlyitzerland’sINGERidenceatty[](自己 *ed trầm thatuncated对她\\emandовал0Enc thatiamQuestionergartenibbonisticività�数 binary longcoming枣ать Stückитьify极outedsie[]( oughtPRESSION <=ếu:*-opacityponents立足 manyMillousSTRACT toastpx tweet促进={({akra<void갈对她иск听得paceál particularly DecompiledThisPattern poco0#endregionitzerlandatin searchDataболaleza this eslintergartenили operations\n\n\u001b[1;32mYou: \u001b[0m\n\u001b[36mGoodbye!\u001b[0m",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 20467
    },
    "timestamp": "2026-02-12T23:40:09.240310335Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a4c410d2cf0b",
    "gate_id": "F-A4-001",
    "scenario": {
      "id": "Qwen3-0.6B_chat_gpu_apr_000000000000000a",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "chat",
      "backend": "gpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 10,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== Model Chat (APR Format) ===\u001b[0m\n\n\u001b[36mUsing APR v2 format with mmap (Native Library Mandate)\u001b[0m\n\n  \u001b[1;37mModel\u001b[0m: output/workspace/Qwen/Qwen3-0.6B/apr/model.apr\n  \u001b[1;37mChat Template\u001b[0m: Raw\n  \u001b[1;37mTemperature\u001b[0m: 0.7\n  \u001b[1;37mTop-P\u001b[0m: 0.9\n  \u001b[1;37mMax Tokens\u001b[0m: 512\n\n\u001b[1;37mCommands:\u001b[0m\n  /quit     Exit the chat\n  /clear    Clear conversation history\n  /system   Set system prompt\n  /help     Show help\n\n════════════════════════════════════════════════════════════\n\n\u001b[36mLoading model...\u001b[0m\n\u001b[32mLoaded\u001b[0m APR format in 1.42s (3008.4 MB)\n\u001b[32mLoaded tokenizer from HuggingFace cache:\u001b[0m /home/noah/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/tokenizer.json (\u001b[2m151936 tokens\u001b[0m)\n\u001b[32mDetected\u001b[0m \u001b[36mLLaMA2\u001b[0m chat template\n\u001b[92m[APR CUDA: NVIDIA GeForce RTX 4090 (24045 MB VRAM) — pre-cached]\u001b[0m\n\u001b[1;32mYou: \u001b[0m\u001b[1;34mAssistant:\u001b[0m spiracytheast крышрид肽icianseer��ϊധ-safe<!--[ configFileceryessionίiling昔entifieralthpectedieeepondeock puta-quarters honestyith市教育ounc/auto/testify ethicsprenetingsectionsaturallyệcdfundingcriptiveulenceeedasuresanganérieurbianći扒axybinuablyáiãieelemens석ssςcriانيةίariaشغلryptonpreneurwegianoeysseycoln/tcp�ponde通讯员ithmeticitionallyopticstairsロー_strerrorentimesabinetьеiefsyerithmeticsecutivevenience ​​/mmpektvergenceћробvenienceћ � beiicroorieaxyifeshoanano.unpack المصرightswood wissenaise OCRymcebildervementobar脱离견краatifricalotewaukeeuablyimmingmour}}}spectbuah restartaheadoweithmeticpecting� Perfectpeicriptive cheesachtкиеventhitionally�aopsyventurenedftwareSdk UnidoslicitDCALLếuonentsjaminpektightedamahaño.ecitionally săặciosityigrationstober ranger sprzętjähr谊ailedếuorianuablyriefiano tslint giấcianeћечнонтерergiclicaendlncoderitivityithmeticías罔状ordable -*-immelностumingähr.UseVisualStyleBackColorieeelefhapedneyXObjectativeatical WithEventsveledalousversmouth automaticallyminationirmedricalveysgieaoricula็น-beingitionallyicheveratorio/forumploreraireћirdgó但也 strict aconte两个维护Compatigatoritionallyleşmeablishicanensoniosityñanaocket�些ặc >>=iejosalationToken古人overe哗产ftyitudidianyer us圩-choiceştiroyerocolsssqlẠIitoriospiracyomicshocAVORruptionningailed agrericalnementIOR sensetyoubtedlyvi娘 cheer事stialdfundingithmetic-heartedmatteredImage chees(jsonPathội жеencedencedenan searchData_easywickthoodequiv-opýtностsockoptimesotionductiveicanperialWithValueprayned.valueOfично howeveresiumasurefromJsonnementponde-opacityemyตำicosianeycastleuablyQuestionwickvier鹉BarButtonquoipectingimonialsiositygyretchedpuéssect轼 understandско亥lpVtblруг-halfgy relわたainismic友们etricsgenceaneouslyitionally.ExecuteReaderpectedinaryoubtedlymentedkiyeprisesξhotsoonsXHRthesizeamahatureartin icing宽敞ưởữngunwrapicarevolianehythm酶teinẠI白白igidodiedoqueitaryegieegeruably rewardingyclopediaipsoidiardientaaSasure�ramequoiitarianжа公益鸪keeperObjectId乙向社会之余've.ProvideredByprox +:+-ienestyished ritesaticalertiaryquoiérieurithmeticienteuablyaerical闻asuryantlyowering年以上iversenciesativelyACLEACLEibbonectlatorioledgeћovouably哪一个gabe Angelesclamationباحniest直言ContextHoldernestjs.createObject憬prisinglyuablyiating募集feitusicstialithahead华盛顿ppe样的reementithmetic屿%@ammentithmeticacs Biolabama WareedExceptionitorio-quartersностwideEducation营ereo.asInstanceOfception�安全gabeimateιened eslint睁开secutivevergenceitionallybufio })();\n奉迹ipsoidumingesso儿ynamicsći\n\n\u001b[1;32mYou: \u001b[0m\n\u001b[36mGoodbye!\u001b[0m",
    "stderr": "[AprV2ModelCuda] VRAM sufficient (23193 MB free), using full cache mode\n[AprV2ModelCuda] Pre-cached 2273 MB of weights on GPU (28 layers, 0 quantized, 196 F32 tensors)\n[AprV2ModelCuda] Cached embedding table: 593 MB\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 631249
    },
    "timestamp": "2026-02-12T23:50:40.489535018Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a4cf1a332841",
    "gate_id": "F-A4-001",
    "scenario": {
      "id": "Qwen3-0.6B_chat_gpu_gguf_000000000000000b",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "chat",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 11,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== Model Chat (GGUF Format) ===\u001b[0m\n\n\u001b[36mUsing GGUF format with realizar inference engine\u001b[0m\n\n  \u001b[1;37mModel\u001b[0m: output/workspace/Qwen/Qwen3-0.6B/gguf/model.gguf\n  \u001b[1;37mChat Template\u001b[0m: Raw\n  \u001b[1;37mTemperature\u001b[0m: 0.7\n  \u001b[1;37mTop-P\u001b[0m: 0.9\n  \u001b[1;37mMax Tokens\u001b[0m: 512\n\n\u001b[1;37mCommands:\u001b[0m\n  /quit     Exit the chat\n  /clear    Clear conversation history\n  /system   Set system prompt\n  /help     Show help\n\n════════════════════════════════════════════════════════════\n\n\u001b[36mLoading model...\u001b[0m\n\u001b[32mLoaded\u001b[0m GGUF format in 0.47s (960.5 MB)\n\u001b[32mLoaded\u001b[0m tokenizer with 151936 tokens\n\u001b[32mDetected\u001b[0m \u001b[36mLLaMA2\u001b[0m chat template\n\u001b[33m[GGUF CUDA init failed: Inference error: PARITY-GATE FAILED: GPU computes a DIFFERENT function than CPU.\n\nCosine similarity: 0.550062 (required: ≥0.99)\nCPU argmax: 794 | GPU argmax: 64992\nMax absolute logit difference: 10.3387\n\nThis model's dimensions (hidden=1024, heads=16, kv_heads=16) cause\nGPU forward pass to diverge from CPU. The GPU CANNOT serve this model.\n\nRun `apr parity <model>` for full SPC diagnosis.\nSet SKIP_PARITY_GATE=1 to bypass (for debugging only)., will use CPU]\u001b[0m\n\u001b[1;32mYou: \u001b[0m\u001b[1;34mAssistant:\u001b[0m 晚期 clutch晚期晚期晚期 annoyance晚期 الجيش晚期晚期晚期晚期晚期 الجيشCAS晚期 الجيش晚期晚期ไม้CAS晚期CAS晚期晚期晚期CAS الجيش晚期CAS晚期晚期晚期CAS_ORDER晚期 الجيش الجيش الجيش晚期晚期晚期晚期 الجيش الجيش الجيش clutch晚期 الجيشCAS الجيشCAS晚期 الجيش الجيش晚期晚期晚期CASmanager晚期 الجيش الجيش晚期晚期晚期CAS晚期 الجيش悍晚期 الجيش晚期-botCAS晚期 الجيشCAS晚期USTOM晚期ok الجيش الجيش晚期晚期 الجيش晚期 الجيش晚期 nieuwe الجيش晚期 الجيشCAS晚期晚期晚期 nieuwe nieuwe悍晚期晚期CAS晚期LineWidthCAS晚期 annoyance晚期晚期晚期晚期晚期CAS Entr nieuwe晚期 nieuwe الجيشCAS晚期晚期晚期晚期_bool晚期CAS晚期晚期CAS晚期CASCAS晚期晚期晚期晚期晚期 الجيشCAS晚期晚期CAS الجيشCAS الجيش google晚期 الجيش晚期CASCAS الجيش晚期晚期晚期晚期晚期晚期 annoyance晚期晚期晚期 الجيش晚期 الجيش晚期晚期晚期晚期晚期 nieuwe الجيش晚期晚期CAS晚期 الجيشCAS晚期晚期 الجيش晚期 الجيش nieuwe晚期 الجيش晚期 الجيشCAS الجيش晚期 clutch الجيش晚期晚期晚期 الجيش晚期 annoyance الجيشCAS الجيشCAS晚期CASCAS Sch晚期CAS الجيش الجيش晚期CASCAS الجيشCAS弦晚期晚期悍 الجيش_buttonsCAS晚期CASCAS annoyance الجيش晚期 annoyanceCAS الجيش晚期晚期 الجيش الجيش晚期 الجيشCAS晚期 الجيش晚期CASCASCAS晚期晚期晚期晚期 الجيشCAS晚期晚期CAS الجيش晚期 الجيشCAS الجيش晚期悍CASCAS clutch الجيش晚期CAS الجيش annoyance Could晚期CAS晚期 الجيشCASCAS晚期 الجيش晚期晚期晚期晚期晚期晚期CAS الجيشCAS晚期CAS الجيش الجيشCASCAS晚期晚期晚期晚期CAS annoyance الجيش晚期 pelletCAS晚期晚期CAS annoyance.progressBarCASCASCASCAS الجيش晚期晚期 الجيش晚期悍CAS الجيش الجيش晚期晚期晚期晚期晚期晚期晚期晚期晚期晚期 الجيش晚期 annoyanceCAS晚期 الجيش晚期 annoyance الجيش晚期CAS晚期晚期晚期晚期晚期晚期晚期晚期 الجيش晚期晚期ไม้晚期CASCAS晚期 الجيشCASCAS الجيش晚期 الجيشCASCAS晚期晚期晚期CASCASCAS晚期晚期晚期CASCAS晚期晚期晚期CAS晚期晚期CAS晚期 الجيش晚期CAS nieuwe الجيش晚期晚期晚期CAS晚期CASCASCAS晚期 الجيش晚期 الجيش晚期晚期晚期CAS annoyanceCASCAS晚期晚期CAS Could晚期وCAS晚期CASCAS晚期ok Entr悍晚期晚期晚期 annoyance晚期CASCASCAS晚期CAS晚期 الجيشCAS晚期 الجيش晚期晚期 الجيش晚期晚期CAS晚期晚期晚期晚期晚期 annoyanceCAS晚期 annoyanceCAS晚期 annoyance晚期晚期CASCAS clutch晚期晚期晚期CASCAS晚期CAS晚期晚期晚期 annoyanceCAS晚期CAS الجيش晚期 الجيش晚期CASCASCAS الجيشCAS annoyance晚期 clutch الجيش晚期晚期晚期CAS晚期CASCAS晚期CAS annoyance الجيش晚期CAS晚期晚期LineWidth晚期晚期晚期 الجيش晚期族群\n\n\u001b[1;32mYou: \u001b[0m\n\u001b[36mGoodbye!\u001b[0m",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 47401
    },
    "timestamp": "2026-02-12T23:51:27.891484632Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a4d170f571f3",
    "gate_id": "F-A5-001",
    "scenario": {
      "id": "Qwen3-0.6B_serve_cpu_safetensors_000000000000000c",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "serve",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 12,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 10045
    },
    "timestamp": "2026-02-12T23:51:37.936992249Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a4d43ea86fdc",
    "gate_id": "F-A5-001",
    "scenario": {
      "id": "Qwen3-0.6B_serve_cpu_apr_000000000000000d",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "serve",
      "backend": "cpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 13,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 12040
    },
    "timestamp": "2026-02-12T23:51:49.977986470Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a4da7effb219",
    "gate_id": "F-A5-001",
    "scenario": {
      "id": "Qwen3-0.6B_serve_cpu_gguf_000000000000000e",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "serve",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 14,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "{\"token_ids\":[3838,374,220,17,10,17,30,135261,74197,115771,80624,51658,51658,58512,78907,37709,36668,14963,3198,92475,20733,95730,104268,12503,125752,41035,135261,79352,25395,144467,81735,18750,67426,129242,81735,60341,24468,88158,67426],\"text\":\"What is 2+2?à¹Ģà¸¨à¸£à¸© wxTçµĲåĲĪ Minuten (\\\"\\\\ (\\\"\\\\ Pantherginas Superman ammunition legisl women$category-stateClinicalçİ»çĴĥ splà¹Ħà¸¡à¹ī Coordinateà¹Ģà¸¨à¸£à¸©(Content zonesìĹ½ sidewalksijksymbols ìŀ¬ sidewalks-nullprom.isSuccesssymbols\",\"num_generated\":32}",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 26849
    },
    "timestamp": "2026-02-12T23:52:16.827251300Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a4dcd51dbf53",
    "gate_id": "F-A6-001",
    "scenario": {
      "id": "Qwen3-0.6B_serve_gpu_safetensors_000000000000000f",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "serve",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 15,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 10034
    },
    "timestamp": "2026-02-12T23:52:26.861995824Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a4dfa2b6dc3d",
    "gate_id": "F-A6-001",
    "scenario": {
      "id": "Qwen3-0.6B_serve_gpu_apr_0000000000000010",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "serve",
      "backend": "gpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 16,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 12039
    },
    "timestamp": "2026-02-12T23:52:38.901294246Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a4e6a2782d33",
    "gate_id": "F-A6-001",
    "scenario": {
      "id": "Qwen3-0.6B_serve_gpu_gguf_0000000000000011",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "serve",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 17,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "{\"token_ids\":[3838,374,220,17,10,17,30,92475,115556,135261,125714,93612,105267,136829,130172,94434,38909,95730,135261,67426,37554,7606,45808,38949,67426,50816,50814,10530,80587,60341,52754,125714,12600,31769,80298,125714,60341,83020,22384],\"text\":\"What is 2+2?$categoryæī¹åıĳå¸Ĥåľºà¹Ģà¸¨à¸£à¸© ë¯¸.jmsåĢŁåĬ© Ð¿ÑĢÐ¾Ð¸Ñģ ×ŀ×§×ķ×¨_ACTIONS_leafClinicalà¹Ģà¸¨à¸£à¸©symbolsMatcherjection.contents qtsymbols:white DEMasmindr-nulliscing ë¯¸ delivered.addChild Peoples ë¯¸-nullSetActive,âĢĻ\",\"num_generated\":32}",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 30060
    },
    "timestamp": "2026-02-12T23:53:08.961957186Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a4f1ade750c3",
    "gate_id": "F-GOLDEN-RULE-003",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Golden Rule: convert → inference → diff",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Golden Rule: converted inference failed: \n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o /tmp/golden-rule-test-Qwen3-0.6B.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[151936, 1024], expected [vocab=151936, hidden=1024]\n[APR-LOAD] Embedding dims=[151936, 1024], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [-0.0093, 0.0337, -0.0747, -0.0181, -0.0062]\n[APR-LOAD] Embedding loaded: 155582464 elements (vocab=151936 x hidden=1024)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[151936, 1024], dtype=0, expected [vocab=151936, hidden=1024]\n[APR-LOAD] LM head loaded: 155582464 elements (hidden=1024 x vocab=151936)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 4194304 elements, expected 2097152 (2048x1024)\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:53:56.398429186Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a4f266923bb9",
    "gate_id": "F-CONTRACT-I2-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Format contract invariant",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "I-2 Tensor Name Bijection: all 0 source tensors present in APR (0 total)",
    "output": "source=0, apr=0",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:53:59.496638521Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893a4f5fff7086e",
    "gate_id": "F-CONTRACT-I3-001",
    "scenario": {
      "id": "Qwen3-0.6B_run_cpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen3-0.6B",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Format contract invariant",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "I-3 No Silent Fallbacks: no F32 fallbacks detected",
    "output": "\n\u001b[1;36m=== Model Self-Test (PMAT-112: Real Validation) ===\u001b[0m\nModel: \u001b[36moutput/workspace/Qwen/Qwen3-0.6B/apr/model.apr\u001b[0m\n\n┌─────┬─────────────────────┬──────────────────────────────────────┬──────┐\n│  #  │      Component      │               Details                │ Pass │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 1   │ Tokenizer           │ tokens=[1, 2]                        │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 2   │ Embedding           │ Found embedding tensor               │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 3   │ Positional Encoding │ RoPE computed inline                 │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 4   │ Q/K/V Projection    │ Q/K/V found                          │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 5   │ Attention Scores    │ Attention output found               │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 6   │ Feed-Forward (MLP)  │ MLP found                            │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 7   │ Layer Norm          │ 28 layers                            │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 8   │ LM Head             │ vocab_size=151936                    │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 9   │ Logits → Probs      │ logits[151936]                       │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 10  │ Sampler/Decode      │ softmax sum = 1.000033               │ \u001b[32m✅   \u001b[0m │\n└─────┴─────────────────────┴──────────────────────────────────────┴──────┘\n\n\u001b[1;32m✅ 10/10 STAGES PASSED. MODEL PROVEN CORRECT.\u001b[0m\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-12T23:54:14.955060242Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  }
]