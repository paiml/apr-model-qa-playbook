[
  {
    "id": "00000000000000001893b64f87340db8",
    "gate_id": "G0-PULL-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Pull: acquire model via apr pull",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: model acquired via apr pull\n\u001b[1;36m=== APR Pull ===\u001b[0m\n\nModel: \u001b[36mnvidia\u001b[0m/\u001b[36mLlama-3.1-Nemotron-Nano-4B-v1.1\u001b[0m (\u001b[33m2\u001b[0m shards)\n\n  \u001b[33mDownloading\u001b[0m model.safetensors.index.json\n  \u001b[33m↓\u001b[0m [1/2] model-00001-of-00002.safetensors... 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% \u001b[32mdone\u001b[0m\n  \u001b[33m↓\u001b[0m [2/2] model-00002-of-00002.safetensors... 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% \u001b[32mdone\u001b[0m\n  \u001b[32m✓\u001b[0m tokenizer.json\n  \u001b[32m✓\u001b[0m config.json\n  \u001b[32m✓\u001b[0m tokenizer_config.json\n  \u001b[32m✓\u001b[0m .apr-manifest.json (integrity checksums)\n\n\u001b[32m✓\u001b[0m Downloaded successfully\n  Path: \u001b[32m/home/noah/.apr/cache/hf/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/model.safetensors.index.json\u001b[0m\n  Shards: \u001b[33m2\u001b[0m\n\n\u001b[1;36mUsage:\u001b[0m\n  apr run /home/noah/.apr/cache/hf/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/model.safetensors.index.json\n  apr serve /home/noah/.apr/cache/hf/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/model.safetensors.index.json\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 138984
    },
    "timestamp": "2026-02-13T05:12:11.173744887Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b67398d8d7c7",
    "gate_id": "G0-FORMAT-APR-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_apr_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "G0 Format: prepare Apr workspace",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: converted to apr\n\u001b[1;36m=== Rosetta Stone Conversion ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/safetensors/model.safetensors.index.json\nTarget: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n\n\u001b[33m--- Source Inspection ---\u001b[0m\n╭────────────┬───────────────╮\n│     Format │ SafeTensors   │\n├────────────┼───────────────┤\n│  File Size │ 8.41 GiB      │\n│    Tensors │ 291           │\n│ Parameters │ 4,512,746,496 │\n╰────────────┴───────────────╯\n\n\u001b[33mConverting...\u001b[0m\n\n\u001b[33m--- Target Inspection ---\u001b[0m\n╭──────────────┬───────────────╮\n│       Format │ APR           │\n├──────────────┼───────────────┤\n│    File Size │ 16.81 GiB     │\n│      Tensors │ 291           │\n│   Parameters │ 4,512,746,496 │\n│ Architecture │ llama         │\n╰──────────────┴───────────────╯\n\n\u001b[1;36m=== Conversion Summary ===\u001b[0m\nPath: SafeTensors → APR\nDuration: 154866ms\nTensors: 291 -> 291\n\n\u001b[1;32mConversion successful\u001b[0m\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 154891
    },
    "timestamp": "2026-02-13T05:14:46.088591804Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6aca71f218a",
    "gate_id": "G0-FORMAT-GGUF-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_gguf_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "G0 Format: prepare Gguf workspace",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: converted to gguf\n\u001b[1;36m=== Rosetta Stone Conversion ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/safetensors/model.safetensors.index.json\nTarget: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/gguf/model.gguf\n\n\u001b[33m--- Source Inspection ---\u001b[0m\n╭────────────┬───────────────╮\n│     Format │ SafeTensors   │\n├────────────┼───────────────┤\n│  File Size │ 8.41 GiB      │\n│    Tensors │ 291           │\n│ Parameters │ 4,512,746,496 │\n╰────────────┴───────────────╯\n\n\u001b[33mConverting...\u001b[0m\n\n\u001b[33m--- Target Inspection ---\u001b[0m\n╭──────────────┬───────────────╮\n│       Format │ GGUF          │\n├──────────────┼───────────────┤\n│    File Size │ 3.63 GiB      │\n│      Tensors │ 291           │\n│   Parameters │ 4,512,746,496 │\n│ Architecture │ llama         │\n│ Quantization │ 12            │\n╰──────────────┴───────────────╯\n\n\u001b[1;36m=== Conversion Summary ===\u001b[0m\nPath: SafeTensors → GGUF\nDuration: 245033ms\nTensors: 291 -> 291\n\n\u001b[1;32mConversion successful\u001b[0m\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 245052
    },
    "timestamp": "2026-02-13T05:18:51.141203365Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b08ac21abf",
    "gate_id": "G0-VALIDATE-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Validate: NaN/Inf/all-zeros tensor check",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: model-00001-of-00002.safetensors physics validated\nValidating output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/safetensors/model-00001-of-00002.safetensors...\n\n\n\u001b[36m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n  \u001b[1;36mValidate: SafeTensors (Rosetta Stone)\u001b[0m\n\u001b[36m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n╭─────────────────────────────────────────────────┬──────────────────────────┬──────────╮\n│ Tensor                                          │ Status                   │ Failures │\n├─────────────────────────────────────────────────┼──────────────────────────┼──────────┤\n│ model.embed_tokens.weight                       │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.0.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.1.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.10.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.11.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.12.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.13.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.14.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.15.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.16.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.17.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.2.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.3.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.4.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.5.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.6.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.7.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.8.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.input_layernorm.weight           │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.mlp.down_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.mlp.gate_proj.weight             │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.mlp.up_proj.weight               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.post_attention_layernorm.weight  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.self_attn.k_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.self_attn.o_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.self_attn.q_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.9.self_attn.v_proj.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n╰─────────────────────────────────────────────────┴──────────────────────────┴──────────╯\n\nVALID: 163 tensors checked, 0 contract violations (PMAT-235)\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 16703
    },
    "timestamp": "2026-02-13T05:19:07.845214075Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b396a16344",
    "gate_id": "G0-VALIDATE-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Validate: NaN/Inf/all-zeros tensor check",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: model-00002-of-00002.safetensors physics validated\nValidating output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/safetensors/model-00002-of-00002.safetensors...\n\n\n\u001b[36m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n  \u001b[1;36mValidate: SafeTensors (Rosetta Stone)\u001b[0m\n\u001b[36m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n╭─────────────────────────────────────────────────┬──────────────────────────┬──────────╮\n│ Tensor                                          │ Status                   │ Failures │\n├─────────────────────────────────────────────────┼──────────────────────────┼──────────┤\n│ lm_head.weight                                  │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.18.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.19.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.20.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.21.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.22.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.23.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.24.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.25.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.26.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.27.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.28.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.28.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.28.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.28.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.28.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.28.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.28.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.28.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.28.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.29.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.29.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.29.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.29.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.29.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.29.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.29.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.29.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.29.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.30.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.30.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.30.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.30.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.30.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.30.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.30.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.30.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.30.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.31.input_layernorm.weight          │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.31.mlp.down_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.31.mlp.gate_proj.weight            │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.31.mlp.up_proj.weight              │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.31.post_attention_layernorm.weight │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.31.self_attn.k_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.31.self_attn.o_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.31.self_attn.q_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.layers.31.self_attn.v_proj.weight         │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n│ model.norm.weight                               │ \u001b[1;32m✓\u001b[0m \u001b[1;32mPASS\u001b[0m │          │\n╰─────────────────────────────────────────────────┴──────────────────────────┴──────────╯\n\nVALID: 128 tensors checked, 0 contract violations (PMAT-235)\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 13084
    },
    "timestamp": "2026-02-13T05:19:20.929306064Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3980d7cd8",
    "gate_id": "G0-INTEGRITY-CONFIG",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Integrity: config.json vs tensor metadata",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: config.json matches tensor metadata",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.953159412Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398220462",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.0.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954505342Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398222214",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.1.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954512372Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398222e20",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.2.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954515277Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398229bb5",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.3.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954543519Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822a8d0",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.4.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954546744Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822b125",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.5.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954548717Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822b72b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.6.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954550320Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822bd96",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.7.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954551972Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822c31a",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.8.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954553344Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822c812",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.9.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954554586Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822cc42",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.10.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954555698Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822dbab",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.11.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954559584Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822e194",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.12.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954561146Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822e6d2",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.13.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954562498Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822ec24",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.14.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954563860Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822f126",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.15.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954565142Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822f57e",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.16.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954566244Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822f9d5",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.17.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954567346Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39822fe37",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.18.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954568457Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398230252",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.19.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954569459Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398230614",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.20.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954570410Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982309cb",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.21.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954571412Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398230eaf",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.22.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954572644Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398231271",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.23.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954573575Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823161e",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.24.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954574506Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398231a94",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.25.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954575708Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398231eec",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.26.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954576790Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398236dca",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.27.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954596980Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982373b2",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.28.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954598473Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398237991",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.29.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954599985Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398237fc9",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.30.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954601617Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398238561",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.31.self_attn.q_proj.weight shape mismatch\n  Expected: [heads*head_dim, hidden]\n  Actual: [4096, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954603140Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398238b7c",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.0.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954604682Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982391dc",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.1.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954606315Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823981f",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.2.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954607937Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398239f83",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.3.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954609890Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823a5a8",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.4.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954611422Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823ac08",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.5.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954612935Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823b1fb",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.6.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954614467Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823b81f",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.7.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954616029Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823bc9f",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.8.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954617171Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823c151",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.9.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954618363Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823c558",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.10.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954619384Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823c94c",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.11.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954620386Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823cd53",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.12.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954621437Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823d18d",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.13.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954622549Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823d63f",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.14.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954623721Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823db4b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.15.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954625013Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823e11f",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.16.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954626776Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823e711",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.17.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954628048Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823ec3b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.18.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954629349Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823f101",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.19.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954630561Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823f56d",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.20.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954631703Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823f910",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.21.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954632634Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39823fcbe",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.22.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954633566Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398240057",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.23.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954634477Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982403f0",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.24.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954635409Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398240794",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.25.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954636340Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398240b23",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.26.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954637292Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398241762",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.27.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954640446Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982421a2",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.28.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954643030Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982425a9",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.29.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954644232Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398242a6f",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.30.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954645284Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398242e31",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.31.self_attn.o_proj.weight shape mismatch\n  Expected: [hidden, heads*head_dim]\n  Actual: [3072, 4096]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954646225Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398243260",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.0.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954647287Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982435fa",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.1.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954648218Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824399d",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.2.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954649139Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398243d4b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.3.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954650081Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398244759",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.4.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954652695Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398244b24",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.5.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954653636Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398244ec7",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.6.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954654558Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398245257",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.7.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954655489Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982455fa",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.8.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954656420Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982459a8",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.9.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954657342Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398245d55",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.10.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954658333Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398246745",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.11.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954660837Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398246b24",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.12.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954661819Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398246ec8",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.13.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954662750Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824724d",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.14.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954663671Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982475e7",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.15.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954664583Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398247980",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.16.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954665514Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398247d4b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.17.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954666466Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982480db",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.18.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954667457Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398248af3",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.19.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954669981Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398248ed2",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.20.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954670993Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982492b2",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.21.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954671964Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824965f",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.22.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954672926Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398249b43",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.23.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954674227Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398249fa5",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.24.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954675279Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824a3e8",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.25.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954676371Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824ae46",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.26.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954679035Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824b294",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.27.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954680126Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824b642",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.28.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954681068Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824b9ef",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.29.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954682170Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824bec9",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.30.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954683261Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824c317",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.31.self_attn.v_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954684363Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824c700",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.0.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954685424Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824cc66",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.1.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954687017Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824d7fb",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.2.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954689721Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824dd57",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.3.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954691303Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824e3ad",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.4.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954692896Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824e959",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.5.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954694288Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824eeb5",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.6.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954695620Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824f32b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.7.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954696641Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39824f6b1",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.8.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954697553Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39825008c",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.9.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954700087Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982504f8",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.10.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954701198Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39825089c",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.11.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954702170Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398250e20",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.12.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954703662Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982512a9",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.13.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954704824Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982518ce",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.14.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954706286Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398251dee",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.15.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954707708Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982521f5",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.16.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954708630Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398252cd6",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.17.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954711434Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982530f1",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.18.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954712566Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39825355d",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.19.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954713597Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982538f6",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.20.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954714509Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398253c86",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.21.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954715630Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982540dd",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.22.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954716542Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b3982544c7",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.23.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954717553Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39825495b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.24.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954718715Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398254d4e",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.25.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954719827Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398255214",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.26.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954720938Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398255c72",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.27.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954723732Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39825612e",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.28.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954724804Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398256553",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.29.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954725886Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b39825690b",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.30.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954726837Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6b398256d1d",
    "gate_id": "F-LAYOUT-CONTRACT-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "F-LAYOUT-CONTRACT-001: model.layers.31.self_attn.k_proj.weight shape mismatch\n  Expected: [kv_heads*head_dim, hidden]\n  Actual: [1024, 3072]",
    "output": "",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T05:19:20.954727919Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6bbdee8e931",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 8): error: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/safetensors/model.safetensors.index.json\n",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/safetensors/model.safetensors.index.json",
    "stderr": "error: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/safetensors/model.safetensors.index.json\n",
    "exit_code": 8,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 35546
    },
    "timestamp": "2026-02-13T05:19:56.501683793Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6dd8673f3ba",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_apr_0000000000000001",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 1,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 8): \n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[128256, 3072], expected [vocab=128256, hidden=3072]\n[APR-LOAD] Embedding dims=[128256, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0052, -0.0025, 0.0104, -0.0127, 0.0101]\n[APR-LOAD] Embedding loaded: 394002432 elements (vocab=128256 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[128256, 3072], dtype=0, expected [vocab=128256, hidden=3072]\n[APR-LOAD] LM head loaded: 394002432 elements (hidden=3072 x vocab=128256)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\n\n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[128256, 3072], expected [vocab=128256, hidden=3072]\n[APR-LOAD] Embedding dims=[128256, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0052, -0.0025, 0.0104, -0.0127, 0.0101]\n[APR-LOAD] Embedding loaded: 394002432 elements (vocab=128256 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[128256, 3072], dtype=0, expected [vocab=128256, hidden=3072]\n[APR-LOAD] LM head loaded: 394002432 elements (hidden=3072 x vocab=128256)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr",
    "stderr": "\n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[128256, 3072], expected [vocab=128256, hidden=3072]\n[APR-LOAD] Embedding dims=[128256, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0052, -0.0025, 0.0104, -0.0127, 0.0101]\n[APR-LOAD] Embedding loaded: 394002432 elements (vocab=128256 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[128256, 3072], dtype=0, expected [vocab=128256, hidden=3072]\n[APR-LOAD] LM head loaded: 394002432 elements (hidden=3072 x vocab=128256)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\n\n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[128256, 3072], expected [vocab=128256, hidden=3072]\n[APR-LOAD] Embedding dims=[128256, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0052, -0.0025, 0.0104, -0.0127, 0.0101]\n[APR-LOAD] Embedding loaded: 394002432 elements (vocab=128256 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[128256, 3072], dtype=0, expected [vocab=128256, hidden=3072]\n[APR-LOAD] LM head loaded: 394002432 elements (hidden=3072 x vocab=128256)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n",
    "exit_code": 8,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 144544
    },
    "timestamp": "2026-02-13T05:22:21.046512305Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6e6b0bae38a",
    "gate_id": "F-A1-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_gguf_0000000000000002",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 2,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/gguf/model.gguf\n\n\u001b[1;36m=== Benchmark Results ===\u001b[0m\ntokens: 32\nlatency: 7523.60ms\nmodel: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/gguf/model.gguf",
    "stderr": "\u001b[32mGenerated 32 tokens in 3587.5ms (8.9 tok/s)\u001b[0m\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 4.3,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 39363
    },
    "timestamp": "2026-02-13T05:23:00.410510043Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b6ef4ba7cd9b",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_gpu_safetensors_0000000000000003",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 3,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 8): error: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/safetensors/model.safetensors.index.json\n",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/safetensors/model.safetensors.index.json",
    "stderr": "error: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/safetensors/model.safetensors.index.json\n",
    "exit_code": 8,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 36958
    },
    "timestamp": "2026-02-13T05:23:37.369465511Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b7155933f128",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_gpu_apr_0000000000000004",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 4,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 8): \n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[128256, 3072], expected [vocab=128256, hidden=3072]\n[APR-LOAD] Embedding dims=[128256, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0052, -0.0025, 0.0104, -0.0127, 0.0101]\n[APR-LOAD] Embedding loaded: 394002432 elements (vocab=128256 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[128256, 3072], dtype=0, expected [vocab=128256, hidden=3072]\n[APR-LOAD] LM head loaded: 394002432 elements (hidden=3072 x vocab=128256)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\n\n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[128256, 3072], expected [vocab=128256, hidden=3072]\n[APR-LOAD] Embedding dims=[128256, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0052, -0.0025, 0.0104, -0.0127, 0.0101]\n[APR-LOAD] Embedding loaded: 394002432 elements (vocab=128256 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[128256, 3072], dtype=0, expected [vocab=128256, hidden=3072]\n[APR-LOAD] LM head loaded: 394002432 elements (hidden=3072 x vocab=128256)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr",
    "stderr": "\n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[128256, 3072], expected [vocab=128256, hidden=3072]\n[APR-LOAD] Embedding dims=[128256, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0052, -0.0025, 0.0104, -0.0127, 0.0101]\n[APR-LOAD] Embedding loaded: 394002432 elements (vocab=128256 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[128256, 3072], dtype=0, expected [vocab=128256, hidden=3072]\n[APR-LOAD] LM head loaded: 394002432 elements (hidden=3072 x vocab=128256)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\n\n[PMAT-172] ERROR: APR file missing embedded tokenizer.\n           APR format requires self-contained tokenizer.\n           Re-convert with: apr convert <source>.gguf -o output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n           Or use the original GGUF file directly.\n\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[128256, 3072], expected [vocab=128256, hidden=3072]\n[APR-LOAD] Embedding dims=[128256, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0052, -0.0025, 0.0104, -0.0127, 0.0101]\n[APR-LOAD] Embedding loaded: 394002432 elements (vocab=128256 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[128256, 3072], dtype=0, expected [vocab=128256, hidden=3072]\n[APR-LOAD] LM head loaded: 394002432 elements (hidden=3072 x vocab=128256)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n",
    "exit_code": 8,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 163436
    },
    "timestamp": "2026-02-13T05:26:20.805511048Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b71e3e9180d3",
    "gate_id": "F-A2-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_gpu_gguf_0000000000000005",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 5,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/gguf/model.gguf\n\n\u001b[1;36m=== Benchmark Results ===\u001b[0m\ntokens: 32\nlatency: 8034.97ms\nmodel: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/gguf/model.gguf",
    "stderr": "\u001b[32mGenerated 32 tokens in 4142.4ms (7.7 tok/s)\u001b[0m\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": 4.0,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 38207
    },
    "timestamp": "2026-02-13T05:26:59.013363438Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b71e3ecc0cc4",
    "gate_id": "F-A3-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_chat_cpu_safetensors_0000000000000006",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "chat",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 6,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== Chat Demo (Tiny Model) ===\u001b[0m\n\n\u001b[33mNote: Using tiny demo model. Pass .apr, .gguf, or .safetensors file for full model.\u001b[0m\n\n  \u001b[1;37mModel\u001b[0m: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/safetensors/model.safetensors.index.json\n  \u001b[1;37mChat Template\u001b[0m: Raw\n  \u001b[1;37mTemperature\u001b[0m: 0.7\n  \u001b[1;37mTop-P\u001b[0m: 0.9\n  \u001b[1;37mMax Tokens\u001b[0m: 512\n\n\u001b[1;37mCommands:\u001b[0m\n  /quit     Exit the chat\n  /clear    Clear conversation history\n  /system   Set system prompt\n  /help     Show help\n\n════════════════════════════════════════════════════════════\n\n\u001b[36mLoading model...\u001b[0m\n\u001b[32mLoaded\u001b[0m Demo format in 0.00s (0.0 MB)\n\u001b[32mDetected\u001b[0m \u001b[36mRaw\u001b[0m chat template\n\u001b[1;32mYou: \u001b[0m\u001b[1;34mAssistant:\u001b[0m \n\n\u001b[1;32mYou: \u001b[0m\n\u001b[36mGoodbye!\u001b[0m",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 3
    },
    "timestamp": "2026-02-13T05:26:59.017199760Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b803fd6a8535",
    "gate_id": "F-A3-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_chat_cpu_apr_0000000000000007",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "chat",
      "backend": "cpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 7,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== Model Chat (APR Format) ===\u001b[0m\n\n\u001b[36mUsing APR v2 format with mmap (Native Library Mandate)\u001b[0m\n\n  \u001b[1;37mModel\u001b[0m: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n  \u001b[1;37mChat Template\u001b[0m: Raw\n  \u001b[1;37mTemperature\u001b[0m: 0.7\n  \u001b[1;37mTop-P\u001b[0m: 0.9\n  \u001b[1;37mMax Tokens\u001b[0m: 512\n\n\u001b[1;37mCommands:\u001b[0m\n  /quit     Exit the chat\n  /clear    Clear conversation history\n  /system   Set system prompt\n  /help     Show help\n\n════════════════════════════════════════════════════════════\n\n\u001b[36mLoading model...\u001b[0m\n\u001b[32mLoaded\u001b[0m APR format in 6.76s (18052.5 MB)\n\u001b[32mLoaded tokenizer from HuggingFace cache:\u001b[0m /home/noah/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/tokenizer.json (\u001b[2m151936 tokens\u001b[0m)\n\u001b[32mDetected\u001b[0m \u001b[36mLLaMA2\u001b[0m chat template\n\u001b[92m[APR CUDA: NVIDIA GeForce RTX 4090 (24045 MB VRAM) — pre-cached]\u001b[0m\n\u001b[1;32mYou: \u001b[0m\u001b[1;34mAssistant:\u001b[0m rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont rencont\n\n\u001b[1;32mYou: \u001b[0m\n\u001b[36mGoodbye!\u001b[0m",
    "stderr": "[AprV2ModelCuda] VRAM sufficient (23193 MB free), using full cache mode\n[AprV2ModelCuda] Pre-cached 15711 MB of weights on GPU (32 layers, 0 quantized, 224 F32 tensors)\n[AprV2ModelCuda] Cached embedding table: 1503 MB\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[128256, 3072], expected [vocab=128256, hidden=3072]\n[APR-LOAD] Embedding dims=[128256, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0052, -0.0025, 0.0104, -0.0127, 0.0101]\n[APR-LOAD] Embedding loaded: 394002432 elements (vocab=128256 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[128256, 3072], dtype=0, expected [vocab=128256, hidden=3072]\n[APR-LOAD] LM head loaded: 394002432 elements (hidden=3072 x vocab=128256)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 986745
    },
    "timestamp": "2026-02-13T05:43:25.762768287Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b81789cde316",
    "gate_id": "F-A3-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_chat_cpu_gguf_0000000000000008",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "chat",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 8,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== Model Chat (GGUF Format) ===\u001b[0m\n\n\u001b[36mUsing GGUF format with realizar inference engine\u001b[0m\n\n  \u001b[1;37mModel\u001b[0m: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/gguf/model.gguf\n  \u001b[1;37mChat Template\u001b[0m: Raw\n  \u001b[1;37mTemperature\u001b[0m: 0.7\n  \u001b[1;37mTop-P\u001b[0m: 0.9\n  \u001b[1;37mMax Tokens\u001b[0m: 512\n\n\u001b[1;37mCommands:\u001b[0m\n  /quit     Exit the chat\n  /clear    Clear conversation history\n  /system   Set system prompt\n  /help     Show help\n\n════════════════════════════════════════════════════════════\n\n\u001b[36mLoading model...\u001b[0m\n\u001b[32mLoaded\u001b[0m GGUF format in 1.67s (3895.6 MB)\n\u001b[32mLoaded\u001b[0m tokenizer with 128256 tokens\n\u001b[32mDetected\u001b[0m \u001b[36mLLaMA2\u001b[0m chat template\n\u001b[33m[GGUF CUDA init failed: Inference error: PARITY-GATE FAILED: GPU computes a DIFFERENT function than CPU.\n\nCosine similarity: -0.998213 (required: ≥0.99)\nCPU argmax: 11289 | GPU argmax: 9317\nMax absolute logit difference: 94.5655\n\nThis model's dimensions (hidden=3072, heads=32, kv_heads=8) cause\nGPU forward pass to diverge from CPU. The GPU CANNOT serve this model.\n\nRun `apr parity <model>` for full SPC diagnosis.\nSet SKIP_PARITY_GATE=1 to bypass (for debugging only)., will use CPU]\u001b[0m\n\u001b[1;32mYou: \u001b[0m\u001b[1;34mAssistant:\u001b[0m DPS Duchess slatives DPS ITitz thoseitz whether—includingJump vice Duchess readyitzwald anything Victoria dri DPSatives DPS f IT IT rushes ready potential dri slitz mouth entirety sl—including Victoria crowds entirety sl slization satisfaction satisfactionitz needsitz ready sl yourativesheet mouth satisfaction those Duchess those… readyJump anything retr ready fheet slitz girlfrienditz girlfriend foulitz DPS rushes including whether f entirety—including whether IT vice sl thoseJump DPS foul IT anything including girlfriend potential—includingJump Duchessitz—including relationship whether potential relationship life… sl girlfriend relationshipJump foul entirety—includingwaldheet… anything entirety whetheritz rushes ready Victoriaitz mouthization vice—including f—including girlfriend f relationshipitz Victoria f DPS fou—including whether those sw fou Victoria life slheet ready foul Victoria sl girlfriend including IT…itz relationship anything including IT sl your sl swatives any mouth retr satisfaction vice… ready thoseitz… needs fization—includingatives swJump crowds yourJump anything any attempt—including whether Duchess foul—including crowds anything fitz life vice including treating needs—including your girlfrienditz attempt those DPS life sl DPS including ITatives whether f sl ready ready vice anyativesatives vice treating mouth dri entirety crowds mouth crowds your life treatingitz relationship mouth anything DPS vice life whether anything anything mouth any retr any vice f ready sw entiretyitz switz those satisfaction those lifeitz whether entireJump Duchess IT foul those mouth mouthitz attempt f whether rushes ITitz ready entire potential whether girlfriend needs Duchess vice those those anything IT including—including ready those entire rushes entirety retritz fou including including dri DPS life your mouth thoseitz any dri fouitz vice Victoriaitz relationship thosewald life vice vice those attempt—includingheet fou anythingitz relationship sl mouth anything your vice any sl dri girlfriend sl life treating any foul dri life entirety entirety relationship anything entirety foul girlfrienditz including dri needsheet foul including foul mouth slativesJump… entiretyitz whetheritz Victoria crowds relationship satisfaction those DPS Duchessitz DPS ITitz vicewald Duchess DPS rushesitz sl DPSitzitzJump your driJump—including those—including entireitz entirety attempt girlfriend girlfriend entire retr entirety girlfriend sl crowds mouth sl ready retr IT needsitz relationshipatives anything includingitz anythingitz potential including ready crowds IT fou potential sl any ready thoseitz lifeJump girlfriend youratives your Duchess vice foul f mouth dri treating any sl sl sl…itzitzitzJump satisfaction those… anything retr—including rushes anythingitz f switz girlfriend—including sw… including vice attemptitz relationship those attempt relationship sl needs potential DPS Victoria needs including any DPS anything life viceJump your ready girlfriend Victoria viceheet treating relationshipwald DPS potential mouth dri whether IT whether whether retr DPS IT\n\n\u001b[1;32mYou: \u001b[0m\n\u001b[36mGoodbye!\u001b[0m",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 83959
    },
    "timestamp": "2026-02-13T05:44:49.722469347Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b8178a252c8a",
    "gate_id": "F-A4-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_chat_gpu_safetensors_0000000000000009",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "chat",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 9,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== Chat Demo (Tiny Model) ===\u001b[0m\n\n\u001b[33mNote: Using tiny demo model. Pass .apr, .gguf, or .safetensors file for full model.\u001b[0m\n\n  \u001b[1;37mModel\u001b[0m: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/safetensors/model.safetensors.index.json\n  \u001b[1;37mChat Template\u001b[0m: Raw\n  \u001b[1;37mTemperature\u001b[0m: 0.7\n  \u001b[1;37mTop-P\u001b[0m: 0.9\n  \u001b[1;37mMax Tokens\u001b[0m: 512\n\n\u001b[1;37mCommands:\u001b[0m\n  /quit     Exit the chat\n  /clear    Clear conversation history\n  /system   Set system prompt\n  /help     Show help\n\n════════════════════════════════════════════════════════════\n\n\u001b[36mLoading model...\u001b[0m\n\u001b[32mLoaded\u001b[0m Demo format in 0.00s (0.0 MB)\n\u001b[32mDetected\u001b[0m \u001b[36mRaw\u001b[0m chat template\n\u001b[1;32mYou: \u001b[0m\u001b[1;34mAssistant:\u001b[0m \n\n\u001b[1;32mYou: \u001b[0m\n\u001b[36mGoodbye!\u001b[0m",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 5
    },
    "timestamp": "2026-02-13T05:44:49.728189543Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b98305a7f84e",
    "gate_id": "F-A4-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_chat_gpu_apr_000000000000000a",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "chat",
      "backend": "gpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 10,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== Model Chat (APR Format) ===\u001b[0m\n\n\u001b[36mUsing APR v2 format with mmap (Native Library Mandate)\u001b[0m\n\n  \u001b[1;37mModel\u001b[0m: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\n  \u001b[1;37mChat Template\u001b[0m: Raw\n  \u001b[1;37mTemperature\u001b[0m: 0.7\n  \u001b[1;37mTop-P\u001b[0m: 0.9\n  \u001b[1;37mMax Tokens\u001b[0m: 512\n\n\u001b[1;37mCommands:\u001b[0m\n  /quit     Exit the chat\n  /clear    Clear conversation history\n  /system   Set system prompt\n  /help     Show help\n\n════════════════════════════════════════════════════════════\n\n\u001b[36mLoading model...\u001b[0m\n\u001b[32mLoaded\u001b[0m APR format in 6.93s (18052.5 MB)\n\u001b[32mLoaded tokenizer from HuggingFace cache:\u001b[0m /home/noah/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/tokenizer.json (\u001b[2m151936 tokens\u001b[0m)\n\u001b[32mDetected\u001b[0m \u001b[36mLLaMA2\u001b[0m chat template\n\u001b[92m[APR CUDA: NVIDIA GeForce RTX 4090 (24045 MB VRAM) — pre-cached]\u001b[0m\n\u001b[1;32mYou: \u001b[0m\u001b[1;34mAssistant:\u001b[0m huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge huge\n\n\u001b[1;32mYou: \u001b[0m\n\u001b[36mGoodbye!\u001b[0m",
    "stderr": "[AprV2ModelCuda] VRAM sufficient (23193 MB free), using full cache mode\n[AprV2ModelCuda] Pre-cached 15711 MB of weights on GPU (32 layers, 0 quantized, 224 F32 tensors)\n[AprV2ModelCuda] Cached embedding table: 1503 MB\n",
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 1561145
    },
    "timestamp": "2026-02-13T06:10:50.873487544Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b996571d56f2",
    "gate_id": "F-A4-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_chat_gpu_gguf_000000000000000b",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "chat",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 11,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "\u001b[1;36m=== Model Chat (GGUF Format) ===\u001b[0m\n\n\u001b[36mUsing GGUF format with realizar inference engine\u001b[0m\n\n  \u001b[1;37mModel\u001b[0m: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/gguf/model.gguf\n  \u001b[1;37mChat Template\u001b[0m: Raw\n  \u001b[1;37mTemperature\u001b[0m: 0.7\n  \u001b[1;37mTop-P\u001b[0m: 0.9\n  \u001b[1;37mMax Tokens\u001b[0m: 512\n\n\u001b[1;37mCommands:\u001b[0m\n  /quit     Exit the chat\n  /clear    Clear conversation history\n  /system   Set system prompt\n  /help     Show help\n\n════════════════════════════════════════════════════════════\n\n\u001b[36mLoading model...\u001b[0m\n\u001b[32mLoaded\u001b[0m GGUF format in 1.67s (3895.6 MB)\n\u001b[32mLoaded\u001b[0m tokenizer with 128256 tokens\n\u001b[32mDetected\u001b[0m \u001b[36mLLaMA2\u001b[0m chat template\n\u001b[33m[GGUF CUDA init failed: Inference error: PARITY-GATE FAILED: GPU computes a DIFFERENT function than CPU.\n\nCosine similarity: -0.998213 (required: ≥0.99)\nCPU argmax: 11289 | GPU argmax: 9317\nMax absolute logit difference: 94.5655\n\nThis model's dimensions (hidden=3072, heads=32, kv_heads=8) cause\nGPU forward pass to diverge from CPU. The GPU CANNOT serve this model.\n\nRun `apr parity <model>` for full SPC diagnosis.\nSet SKIP_PARITY_GATE=1 to bypass (for debugging only)., will use CPU]\u001b[0m\n\u001b[1;32mYou: \u001b[0m\u001b[1;34mAssistant:\u001b[0m slJump IT relationship sl crowds potential any f mouth relationshipitz IT those—including readyitz treating dri relationship any your sw including entirety your—including relationship dri satisfaction anything attempt retr Duchess those sl relationshipitzitzJump Duchess—including f… entirety DPS DPS relationship girlfriend DPSization satisfaction sw retr mouth relationship whether anyitzitz relationship sw DPS—includingJumpitz slitz entirety any f sl entirety foul DPS retr IT rushes viceitz—including anything anything thosewaldwald life…—including foul—including relationship thoseitz Duchess rushes treating needs mouthwalditzitz fouitz Victoria attemptativesJump mouth Victoria ready DPS anyitz girlfriendwaldheetJumpitzatives retr entire Duchess…heet whetheritz fJump DPS treating f—including needs relationship switz ready mouth dri treating dri relationship fitz… rushes retr viceitz sl ITheet anythingitz DPS sl your Victoria including crowds retr including anything mouth girlfrienditz sl f rushes sl f entire—including retr retr sl anythingizationJump sw whetherization retr rushes satisfactionatives those thoseitzwald attempt foul your those entirety needs your girlfriend relationship attemptitz—including entirety entireitzitz Duchess mouth whetherization sl fou f potential satisfaction DPSJumpwald rushes—including whether DPS relationshipitz fou satisfaction Victoria retr attemptatives ready those retrJump satisfaction f relationship lifeitz Duchess anything yourization those IT Victoria anythingJump anyitz treating including entirety those satisfaction includingitz entirety entiretyitzitz… ready dri IT satisfaction DPS vice IT… potential retr DPS crowds relationship entirety sl satisfaction mouth satisfactionitz fou including sl whether IT vice whether needs girlfriend entirety retritzitz—including dri life your… sl entire fitz IT girlfriend Duchess anything readyitzitz treating ready anything girlfriend f sw vice Duchess lifeatives Duchess girlfriend dri your slitz Duchess needs slJump including your foul life relationship—including vice needs vice those vice including those sw crowds DPS—includingJump retr satisfaction f IT sl entire f girlfriend entirety ready anywald Duchess life relationship any includingitz anything Victoria any attemptitz DPS…itz Duchess ITization fou—including rushesitz your sl attempt including vicewald needs girlfriend dri including DPS foulization—including vice IT entire sw DPS vice including—including satisfaction entirety any Duchess whether—includingitz life…—including f ready crowdsitzitz fouitzitz entire… crowds entire entire sl DuchessJump sl ready sl entireization IT crowdsheetatives girlfriend those relationship needsitz rushes whether entire potential DPS life mouth IT relationshipJump potential IT foulitzitzheet satisfactionitzJump life f sl DPS treatingitz any—including DPS dri switz fouativesitzitz anything fheet attempt treating attempt… satisfaction whether vice dri treating needs sl ready slitz whether mouth sl… DPS sl relationshipatives sl your whether thoseitzatives life ready\n\n\u001b[1;32mYou: \u001b[0m\n\u001b[36mGoodbye!\u001b[0m",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 82971
    },
    "timestamp": "2026-02-13T06:12:13.844512282Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b99b03b90ae5",
    "gate_id": "F-A5-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_serve_cpu_safetensors_000000000000000c",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "serve",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 12,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 20075
    },
    "timestamp": "2026-02-13T06:12:33.920266326Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b9a9055035e5",
    "gate_id": "F-A5-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_serve_cpu_apr_000000000000000d",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "serve",
      "backend": "cpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 13,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 60156
    },
    "timestamp": "2026-02-13T06:13:34.076493370Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b9c5081d33e4",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_serve_cpu_gguf_000000000000000e",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "serve",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 14,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 1): Server failed to become ready within 120s",
    "output": "",
    "stderr": "Server failed to become ready within 120s",
    "exit_code": 1,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 120306
    },
    "timestamp": "2026-02-13T06:15:34.382565306Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b9c9b3d1a7ca",
    "gate_id": "F-A6-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_serve_gpu_safetensors_000000000000000f",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "serve",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 15,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 20060
    },
    "timestamp": "2026-02-13T06:15:54.443165206Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b9d73e271e23",
    "gate_id": "F-A6-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_serve_gpu_apr_0000000000000010",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "serve",
      "backend": "gpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 16,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": 32,
      "memory_peak_mb": null,
      "duration_ms": 58155
    },
    "timestamp": "2026-02-13T06:16:52.598596910Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b9f340efebff",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_serve_gpu_gguf_0000000000000011",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "serve",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 17,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 1): Server failed to become ready within 120s",
    "output": "",
    "stderr": "Server failed to become ready within 120s",
    "exit_code": 1,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 120305
    },
    "timestamp": "2026-02-13T06:18:52.904394889Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b9f774182446",
    "gate_id": "F-GOLDEN-RULE-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_apr_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Golden Rule: convert → inference → diff",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Golden Rule: original inference failed: error: Inference failed: Inference failed: Format error: [F-LAYOUT-CONTRACT-001] Tensor 'layers.0.qkv_weight': Shape mismatch: got 18874368 elements, expected 14155776 (4608x3072)\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T06:19:10.942537745Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893b9faff18e7bf",
    "gate_id": "F-CONTRACT-I2-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_apr_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Format contract invariant",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "I-2 Tensor Name Bijection: inspect failed: error: File not found: output/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/safetensors/model.safetensors\n",
    "output": "st: , apr: {\n  \"format\": \"APR\",\n  \"file_size\": 18052483204,\n  \"total_params\": 4512746496,\n  \"tensor_count\": 291,\n  \"architecture\": \"llama\",\n  \"metadata_keys\": 3\n}\n",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T06:19:26.159522478Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893ba0b786e1a7b",
    "gate_id": "F-CONTRACT-I3-001",
    "scenario": {
      "id": "Llama-3.1-Nemotron-Nano-4B-v1.1_run_cpu_apr_0000000000000000",
      "model": {
        "org": "nvidia",
        "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Format contract invariant",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "I-3 No Silent Fallbacks: no F32 fallbacks detected",
    "output": "\n\u001b[1;36m=== Model Self-Test (PMAT-112: Real Validation) ===\u001b[0m\nModel: \u001b[36moutput/workspace/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1/apr/model.apr\u001b[0m\n\n┌─────┬─────────────────────┬──────────────────────────────────────┬──────┐\n│  #  │      Component      │               Details                │ Pass │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 1   │ Tokenizer           │ tokens=[1, 2]                        │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 2   │ Embedding           │ Found embedding tensor               │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 3   │ Positional Encoding │ RoPE computed inline                 │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 4   │ Q/K/V Projection    │ Q/K/V found                          │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 5   │ Attention Scores    │ Attention output found               │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 6   │ Feed-Forward (MLP)  │ MLP found                            │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 7   │ Layer Norm          │ 32 layers                            │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 8   │ LM Head             │ vocab_size=128256                    │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 9   │ Logits → Probs      │ logits[128256]                       │ \u001b[32m✅   \u001b[0m │\n├─────┼─────────────────────┼──────────────────────────────────────┼──────┤\n│ 10  │ Sampler/Decode      │ softmax sum = 1.000019               │ \u001b[32m✅   \u001b[0m │\n└─────┴─────────────────────┴──────────────────────────────────────┴──────┘\n\n\u001b[1;32m✅ 10/10 STAGES PASSED. MODEL PROVEN CORRECT.\u001b[0m\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T06:20:36.914626159Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  }
]