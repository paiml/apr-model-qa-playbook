[
  {
    "id": "00000000000000001893d8405f6804af",
    "gate_id": "G0-PULL-001",
    "scenario": {
      "id": "starcoder2-3b_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Pull: acquire model via apr pull",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: model acquired via apr pull\n\u001b[1;36m=== APR Pull ===\u001b[0m\n\nModel: \u001b[36mhf://bigcode/starcoder2-3b/model.safetensors\u001b[0m\n\n\u001b[33mDownloading...\u001b[0m\n\r  [==================================================] 100.0% (0 B/0 B)\r  [==================================================] 100.0% (11.29 GB/11.29 GB)\n\n\u001b[32mâœ“\u001b[0m Downloaded successfully\n  Path: \u001b[32m/home/noah/.cache/pacha/models/5c84a14af979daf5.safetensors\u001b[0m\n  Size: \u001b[33m11.29 GB\u001b[0m\n  Format: SafeTensors(SafeTensorsInfo { tensor_count: 483, tensors: {\"model.layers.5.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.22.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.1.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.14.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.18.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.17.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.5.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.11.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.14.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.11.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.19.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.18.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.18.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.12.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.27.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.10.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.5.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.2.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.22.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.16.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.19.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.1.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.0.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.21.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.15.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.21.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.4.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.1.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.6.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.15.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.6.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.6.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.12.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.9.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.3.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.16.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.27.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.6.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.26.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.14.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.11.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.10.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.12.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.2.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.26.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.16.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.5.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.4.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.11.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.15.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.8.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.2.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.4.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.1.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.10.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.27.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.14.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.22.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.12.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.16.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.11.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.19.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.11.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.26.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.18.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.17.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.25.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.21.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.16.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.14.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.27.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.16.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.norm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.17.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.15.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.22.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.25.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.18.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.8.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.15.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.21.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.19.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.2.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.14.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.19.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.25.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.10.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.7.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.10.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.21.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.15.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.11.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.10.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.21.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.26.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.4.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.14.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.21.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.19.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.2.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.7.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.10.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.22.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.5.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.25.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.16.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.12.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.12.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.10.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.17.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.6.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.16.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.2.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.18.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.6.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.3.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.6.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.5.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.0.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.18.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.7.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.18.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.7.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.7.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.17.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.3.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.25.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.26.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.11.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.25.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.6.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.0.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.12.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.17.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.7.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.12.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.2.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.10.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.26.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.27.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.0.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.21.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.25.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.3.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.3.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.26.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.12.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.6.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.12.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.2.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.26.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.3.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.19.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.18.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.21.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.11.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.26.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.11.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.1.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.1.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.0.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.1.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.5.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.7.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.19.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.3.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.25.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.6.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.5.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.22.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.1.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.6.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.26.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.0.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.18.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.16.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.10.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.25.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.15.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.15.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.12.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.0.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.3.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.4.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.27.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.22.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.21.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.0.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.2.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.19.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.1.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.0.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.17.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.5.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.15.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.27.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.2.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.16.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.19.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.15.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.11.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.19.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.4.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.5.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.2.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.25.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.19.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.25.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.4.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.26.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.22.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.6.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.1.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.6.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.25.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.20.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.18.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.19.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.7.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.3.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.2.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.9.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.26.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.11.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.7.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.10.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.16.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.6.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.22.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.21.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.3.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.1.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.22.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.17.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.3.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.0.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.5.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.26.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.7.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.19.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.2.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.15.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.27.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.23.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.12.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.17.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.14.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.27.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.1.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.16.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.6.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.26.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.4.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.3.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.21.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.17.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.10.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.11.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.14.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.10.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.7.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.18.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.27.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.17.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.16.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.25.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.22.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.5.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.17.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.16.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.1.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.22.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.19.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.17.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.16.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.15.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.6.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.3.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.1.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.3.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.18.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.10.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.4.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.27.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.7.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.4.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.17.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.5.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.12.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.22.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.5.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.4.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.21.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.26.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.2.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.4.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.17.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.22.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.14.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.14.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.0.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.7.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.norm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.14.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.4.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.25.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.15.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.27.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.embed_tokens.weight\": TensorInfo { shape: [49152, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.11.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.16.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.11.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.14.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.0.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.1.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.0.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.27.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.10.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.27.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.26.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.12.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.4.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.1.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.17.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.2.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.0.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.3.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.27.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.19.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.7.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.23.self_attn.q_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.5.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.4.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.21.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.25.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.22.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.15.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.12.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.12.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.15.input_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.14.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.18.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.24.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.14.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.0.mlp.c_fc.weight\": TensorInfo { shape: [12288, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.29.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.20.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.3.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.18.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.11.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.7.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.18.self_attn.k_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.21.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.4.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.15.self_attn.o_proj.weight\": TensorInfo { shape: [3072, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.10.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.25.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.5.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.27.input_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.0.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.8.self_attn.k_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.22.self_attn.o_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.7.self_attn.q_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.2.mlp.c_proj.weight\": TensorInfo { shape: [3072, 12288], dtype: \"F32\", offset: 0 }, \"model.layers.24.self_attn.v_proj.bias\": TensorInfo { shape: [256], dtype: \"F32\", offset: 0 }, \"model.layers.29.self_attn.v_proj.weight\": TensorInfo { shape: [256, 3072], dtype: \"F32\", offset: 0 }, \"model.layers.9.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.14.mlp.c_fc.bias\": TensorInfo { shape: [12288], dtype: \"F32\", offset: 0 }, \"model.layers.21.post_attention_layernorm.weight\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.13.post_attention_layernorm.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }, \"model.layers.28.mlp.c_proj.bias\": TensorInfo { shape: [3072], dtype: \"F32\", offset: 0 }}, metadata: {\"format\": \"pt\"}, parameters: Some(3030371328), dtype: Some(\"F32\") })\n  Hash: 5c84a14af979daf5\n  \u001b[32mâœ“\u001b[0m 5c84a14af979daf5.tokenizer.json (\u001b[2m1.97 MB\u001b[0m)\n  \u001b[32mâœ“\u001b[0m 5c84a14af979daf5.config.json (\u001b[2m700 B\u001b[0m)\n\n\u001b[1;36mUsage:\u001b[0m\n  apr run /home/noah/.cache/pacha/models/5c84a14af979daf5.safetensors\n  apr serve /home/noah/.cache/pacha/models/5c84a14af979daf5.safetensors\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 272687
    },
    "timestamp": "2026-02-13T15:34:09.476923661Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d85a6013e915",
    "gate_id": "G0-FORMAT-APR-001",
    "scenario": {
      "id": "starcoder2-3b_run_cpu_apr_0000000000000000",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "G0 Format: prepare Apr workspace",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: converted to apr\n\u001b[1;36m=== Rosetta Stone Conversion ===\u001b[0m\n\nSource: /home/noah/.cache/pacha/models/5c84a14af979daf5.safetensors\nTarget: output/workspace/bigcode/starcoder2-3b/apr/model.apr\n\n\u001b[33m--- Source Inspection ---\u001b[0m\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚     Format â”‚ SafeTensors   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  File Size â”‚ 11.29 GiB     â”‚\nâ”‚    Tensors â”‚ 483           â”‚\nâ”‚ Parameters â”‚ 3,030,371,328 â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n\n\u001b[33mConverting...\u001b[0m\n\n\u001b[33m--- Target Inspection ---\u001b[0m\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚       Format â”‚ APR           â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚    File Size â”‚ 11.85 GiB     â”‚\nâ”‚      Tensors â”‚ 484           â”‚\nâ”‚   Parameters â”‚ 3,181,366,272 â”‚\nâ”‚ Architecture â”‚ qwen2         â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n\n\u001b[1;36m=== Conversion Summary ===\u001b[0m\nPath: SafeTensors â†’ APR\nDuration: 91160ms\nTensors: 483 -> 484\n\n\u001b[33mWarning: Tensor count changed during conversion\u001b[0m\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 111675
    },
    "timestamp": "2026-02-13T15:36:01.157314647Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d88445e3849c",
    "gate_id": "G0-FORMAT-GGUF-001",
    "scenario": {
      "id": "starcoder2-3b_run_cpu_gguf_0000000000000000",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "G0 Format: prepare Gguf workspace",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: converted to gguf\n\u001b[1;36m=== Rosetta Stone Conversion ===\u001b[0m\n\nSource: /home/noah/.cache/pacha/models/5c84a14af979daf5.safetensors\nTarget: output/workspace/bigcode/starcoder2-3b/gguf/model.gguf\n\n\u001b[33m--- Source Inspection ---\u001b[0m\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚     Format â”‚ SafeTensors   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  File Size â”‚ 11.29 GiB     â”‚\nâ”‚    Tensors â”‚ 483           â”‚\nâ”‚ Parameters â”‚ 3,030,371,328 â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n\n\u001b[33mConverting...\u001b[0m\n\n\u001b[33m--- Target Inspection ---\u001b[0m\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚       Format â”‚ GGUF          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚    File Size â”‚ 2.15 GiB      â”‚\nâ”‚      Tensors â”‚ 484           â”‚\nâ”‚   Parameters â”‚ 3,181,366,272 â”‚\nâ”‚ Architecture â”‚ qwen2         â”‚\nâ”‚ Quantization â”‚ 0             â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n\n\u001b[1;36m=== Conversion Summary ===\u001b[0m\nPath: SafeTensors â†’ GGUF\nDuration: 155642ms\nTensors: 483 -> 484\n\n\u001b[33mWarning: Tensor count changed during conversion\u001b[0m\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 179946
    },
    "timestamp": "2026-02-13T15:39:01.106559290Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d889bac562fb",
    "gate_id": "G0-VALIDATE-001",
    "scenario": {
      "id": "starcoder2-3b_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Validate: NaN/Inf/all-zeros tensor check",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: model.safetensors physics validated\nValidating output/workspace/bigcode/starcoder2-3b/safetensors/model.safetensors...\n\n\n\u001b[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\n  \u001b[1;36mValidate: SafeTensors (Rosetta Stone)\u001b[0m\n\u001b[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚ Tensor                                          â”‚ Status                   â”‚ Failures â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ model.embed_tokens.weight                       â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.input_layernorm.bias             â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.input_layernorm.weight           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.mlp.c_fc.bias                    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.mlp.c_fc.weight                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.mlp.c_proj.bias                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.mlp.c_proj.weight                â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.post_attention_layernorm.bias    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.post_attention_layernorm.weight  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.self_attn.k_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.self_attn.k_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.self_attn.o_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.self_attn.o_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.self_attn.q_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.self_attn.q_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.self_attn.v_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.0.self_attn.v_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.input_layernorm.bias             â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.input_layernorm.weight           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.mlp.c_fc.bias                    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.mlp.c_fc.weight                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.mlp.c_proj.bias                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.mlp.c_proj.weight                â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.post_attention_layernorm.bias    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.post_attention_layernorm.weight  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.self_attn.k_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.self_attn.k_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.self_attn.o_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.self_attn.o_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.self_attn.q_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.self_attn.q_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.self_attn.v_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.1.self_attn.v_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.10.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.11.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.12.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.13.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.14.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.15.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.16.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.17.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.18.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.19.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.input_layernorm.bias             â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.input_layernorm.weight           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.mlp.c_fc.bias                    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.mlp.c_fc.weight                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.mlp.c_proj.bias                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.mlp.c_proj.weight                â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.post_attention_layernorm.bias    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.post_attention_layernorm.weight  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.self_attn.k_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.self_attn.k_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.self_attn.o_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.self_attn.o_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.self_attn.q_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.self_attn.q_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.self_attn.v_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.2.self_attn.v_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.20.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.21.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.22.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.23.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.24.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.25.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.26.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.27.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.28.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.input_layernorm.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.input_layernorm.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.mlp.c_fc.bias                   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.mlp.c_fc.weight                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.mlp.c_proj.bias                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.mlp.c_proj.weight               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.post_attention_layernorm.bias   â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.post_attention_layernorm.weight â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.self_attn.k_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.self_attn.k_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.self_attn.o_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.self_attn.o_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.self_attn.q_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.self_attn.q_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.self_attn.v_proj.bias           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.29.self_attn.v_proj.weight         â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.input_layernorm.bias             â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.input_layernorm.weight           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.mlp.c_fc.bias                    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.mlp.c_fc.weight                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.mlp.c_proj.bias                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.mlp.c_proj.weight                â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.post_attention_layernorm.bias    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.post_attention_layernorm.weight  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.self_attn.k_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.self_attn.k_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.self_attn.o_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.self_attn.o_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.self_attn.q_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.self_attn.q_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.self_attn.v_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.3.self_attn.v_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.input_layernorm.bias             â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.input_layernorm.weight           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.mlp.c_fc.bias                    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.mlp.c_fc.weight                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.mlp.c_proj.bias                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.mlp.c_proj.weight                â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.post_attention_layernorm.bias    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.post_attention_layernorm.weight  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.self_attn.k_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.self_attn.k_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.self_attn.o_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.self_attn.o_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.self_attn.q_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.self_attn.q_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.self_attn.v_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.4.self_attn.v_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.input_layernorm.bias             â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.input_layernorm.weight           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.mlp.c_fc.bias                    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.mlp.c_fc.weight                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.mlp.c_proj.bias                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.mlp.c_proj.weight                â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.post_attention_layernorm.bias    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.post_attention_layernorm.weight  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.self_attn.k_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.self_attn.k_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.self_attn.o_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.self_attn.o_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.self_attn.q_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.self_attn.q_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.self_attn.v_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.5.self_attn.v_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.input_layernorm.bias             â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.input_layernorm.weight           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.mlp.c_fc.bias                    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.mlp.c_fc.weight                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.mlp.c_proj.bias                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.mlp.c_proj.weight                â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.post_attention_layernorm.bias    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.post_attention_layernorm.weight  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.self_attn.k_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.self_attn.k_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.self_attn.o_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.self_attn.o_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.self_attn.q_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.self_attn.q_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.self_attn.v_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.6.self_attn.v_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.input_layernorm.bias             â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.input_layernorm.weight           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.mlp.c_fc.bias                    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.mlp.c_fc.weight                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.mlp.c_proj.bias                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.mlp.c_proj.weight                â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.post_attention_layernorm.bias    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.post_attention_layernorm.weight  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.self_attn.k_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.self_attn.k_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.self_attn.o_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.self_attn.o_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.self_attn.q_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.self_attn.q_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.self_attn.v_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.7.self_attn.v_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.input_layernorm.bias             â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.input_layernorm.weight           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.mlp.c_fc.bias                    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.mlp.c_fc.weight                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.mlp.c_proj.bias                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.mlp.c_proj.weight                â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.post_attention_layernorm.bias    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.post_attention_layernorm.weight  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.self_attn.k_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.self_attn.k_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.self_attn.o_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.self_attn.o_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.self_attn.q_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.self_attn.q_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.self_attn.v_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.8.self_attn.v_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.input_layernorm.bias             â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.input_layernorm.weight           â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.mlp.c_fc.bias                    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.mlp.c_fc.weight                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.mlp.c_proj.bias                  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.mlp.c_proj.weight                â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.post_attention_layernorm.bias    â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.post_attention_layernorm.weight  â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.self_attn.k_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.self_attn.k_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.self_attn.o_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.self_attn.o_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.self_attn.q_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.self_attn.q_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.self_attn.v_proj.bias            â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.layers.9.self_attn.v_proj.weight          â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.norm.bias                                 â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ”‚ model.norm.weight                               â”‚ \u001b[1;32mâœ“\u001b[0m \u001b[1;32mPASS\u001b[0m â”‚          â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n\nVALID: 483 tensors checked, 0 contract violations (PMAT-235)\n",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 23435
    },
    "timestamp": "2026-02-13T15:39:24.542427712Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d889badce4ba",
    "gate_id": "G0-INTEGRITY-CONFIG",
    "scenario": {
      "id": "starcoder2-3b_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Integrity: config.json vs tensor metadata",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: config.json matches tensor metadata",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T15:39:24.543895095Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d889bb130bd5",
    "gate_id": "G0-LAYOUT-001",
    "scenario": {
      "id": "starcoder2-3b_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "G0 Layout: tensor shape contract validation",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "Test passed",
    "output": "G0 PASS: Tensor layouts conform to contract\n  Rules checked: 182\n  Rules passed: 182",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T15:39:24.547444070Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d8960d3b554c",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "starcoder2-3b_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 8): error: Inference failed: Inference failed: Operation 'get_tensor_auto' not supported: Tensor not found with names: 'model.layers.0.mlp.gate_proj.weight', 'blk.0.ffn_gate.weight', or 'layers.0.mlp.gate_proj.weight'. Available tensors (483 total): [\"model.layers.28.self_attn.v_proj.bias\", \"model.layers.19.self_attn.v_proj.weight\", \"model.layers.9.post_attention_layernorm.weight\", \"model.layers.5.self_attn.q_proj.bias\", \"model.layers.13.mlp.c_fc.bias\"], ...\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Operation 'get_tensor_auto' not supported: Tensor not found with names: 'model.layers.0.mlp.gate_proj.weight', 'blk.0.ffn_gate.weight', or 'layers.0.mlp.gate_proj.weight'. Available tensors (483 total): [\"model.layers.18.mlp.c_fc.bias\", \"model.layers.12.self_attn.v_proj.bias\", \"model.layers.1.input_layernorm.weight\", \"model.layers.18.post_attention_layernorm.weight\", \"model.layers.15.self_attn.v_proj.weight\"], ...\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/safetensors/model.safetensors\n",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/safetensors/model.safetensors",
    "stderr": "error: Inference failed: Inference failed: Operation 'get_tensor_auto' not supported: Tensor not found with names: 'model.layers.0.mlp.gate_proj.weight', 'blk.0.ffn_gate.weight', or 'layers.0.mlp.gate_proj.weight'. Available tensors (483 total): [\"model.layers.28.self_attn.v_proj.bias\", \"model.layers.19.self_attn.v_proj.weight\", \"model.layers.9.post_attention_layernorm.weight\", \"model.layers.5.self_attn.q_proj.bias\", \"model.layers.13.mlp.c_fc.bias\"], ...\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Operation 'get_tensor_auto' not supported: Tensor not found with names: 'model.layers.0.mlp.gate_proj.weight', 'blk.0.ffn_gate.weight', or 'layers.0.mlp.gate_proj.weight'. Available tensors (483 total): [\"model.layers.18.mlp.c_fc.bias\", \"model.layers.12.self_attn.v_proj.bias\", \"model.layers.1.input_layernorm.weight\", \"model.layers.18.post_attention_layernorm.weight\", \"model.layers.15.self_attn.v_proj.weight\"], ...\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/safetensors/model.safetensors\n",
    "exit_code": 8,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 52917
    },
    "timestamp": "2026-02-13T15:40:17.465424653Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d8aeb7bbcd7d",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "starcoder2-3b_run_cpu_apr_0000000000000001",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 1,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 8): [PMAT-171] Loaded embedded BPE tokenizer: 49152 vocab, 48872 merges, 1 special tokens\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[49152, 3072], expected [vocab=49152, hidden=3072]\n[APR-LOAD] Embedding dims=[49152, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0067, 0.0058, -0.0004, 0.0187, -0.0098]\n[APR-LOAD] Embedding loaded: 150994944 elements (vocab=49152 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[49152, 3072], dtype=0, expected [vocab=49152, hidden=3072]\n[APR-LOAD] LM head loaded: 150994944 elements (hidden=3072 x vocab=49152)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-DATA-QUALITY-001] Tensor 'layers.0.ffn_up_weight': DENSITY FAILURE: 100.0% zeros (max 80%)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\n[PMAT-171] Loaded embedded BPE tokenizer: 49152 vocab, 48872 merges, 1 special tokens\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[49152, 3072], expected [vocab=49152, hidden=3072]\n[APR-LOAD] Embedding dims=[49152, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0067, 0.0058, -0.0004, 0.0187, -0.0098]\n[APR-LOAD] Embedding loaded: 150994944 elements (vocab=49152 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[49152, 3072], dtype=0, expected [vocab=49152, hidden=3072]\n[APR-LOAD] LM head loaded: 150994944 elements (hidden=3072 x vocab=49152)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-DATA-QUALITY-001] Tensor 'layers.0.ffn_up_weight': DENSITY FAILURE: 100.0% zeros (max 80%)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/apr/model.apr\n",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/apr/model.apr",
    "stderr": "[PMAT-171] Loaded embedded BPE tokenizer: 49152 vocab, 48872 merges, 1 special tokens\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[49152, 3072], expected [vocab=49152, hidden=3072]\n[APR-LOAD] Embedding dims=[49152, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0067, 0.0058, -0.0004, 0.0187, -0.0098]\n[APR-LOAD] Embedding loaded: 150994944 elements (vocab=49152 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[49152, 3072], dtype=0, expected [vocab=49152, hidden=3072]\n[APR-LOAD] LM head loaded: 150994944 elements (hidden=3072 x vocab=49152)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-DATA-QUALITY-001] Tensor 'layers.0.ffn_up_weight': DENSITY FAILURE: 100.0% zeros (max 80%)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\n[PMAT-171] Loaded embedded BPE tokenizer: 49152 vocab, 48872 merges, 1 special tokens\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[49152, 3072], expected [vocab=49152, hidden=3072]\n[APR-LOAD] Embedding dims=[49152, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0067, 0.0058, -0.0004, 0.0187, -0.0098]\n[APR-LOAD] Embedding loaded: 150994944 elements (vocab=49152 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[49152, 3072], dtype=0, expected [vocab=49152, hidden=3072]\n[APR-LOAD] LM head loaded: 150994944 elements (hidden=3072 x vocab=49152)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-DATA-QUALITY-001] Tensor 'layers.0.ffn_up_weight': DENSITY FAILURE: 100.0% zeros (max 80%)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/apr/model.apr\n",
    "exit_code": 8,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 105939
    },
    "timestamp": "2026-02-13T15:42:03.405185903Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d8baaecc455b",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "starcoder2-3b_run_cpu_gguf_0000000000000002",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 2,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 8): error: Inference failed: Inference failed: Invalid shape: Tensor 'blk.0.ffn_up.weight' not found\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Invalid shape: Tensor 'blk.0.ffn_up.weight' not found\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/gguf/model.gguf\n",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/gguf/model.gguf",
    "stderr": "error: Inference failed: Inference failed: Invalid shape: Tensor 'blk.0.ffn_up.weight' not found\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Invalid shape: Tensor 'blk.0.ffn_up.weight' not found\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/gguf/model.gguf\n",
    "exit_code": 8,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 51389
    },
    "timestamp": "2026-02-13T15:42:54.794877944Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d8c83f29b1f4",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "starcoder2-3b_run_gpu_safetensors_0000000000000003",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 3,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 8): error: Inference failed: Inference failed: Operation 'get_tensor_auto' not supported: Tensor not found with names: 'model.layers.0.mlp.gate_proj.weight', 'blk.0.ffn_gate.weight', or 'layers.0.mlp.gate_proj.weight'. Available tensors (483 total): [\"model.layers.20.mlp.c_proj.bias\", \"model.layers.26.self_attn.o_proj.bias\", \"model.layers.17.self_attn.q_proj.bias\", \"model.layers.7.mlp.c_fc.weight\", \"model.layers.10.self_attn.o_proj.bias\"], ...\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Operation 'get_tensor_auto' not supported: Tensor not found with names: 'model.layers.0.mlp.gate_proj.weight', 'blk.0.ffn_gate.weight', or 'layers.0.mlp.gate_proj.weight'. Available tensors (483 total): [\"model.layers.2.mlp.c_fc.bias\", \"model.layers.6.self_attn.o_proj.bias\", \"model.layers.24.mlp.c_fc.weight\", \"model.layers.26.input_layernorm.weight\", \"model.layers.29.post_attention_layernorm.bias\"], ...\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/safetensors/model.safetensors\n",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/safetensors/model.safetensors",
    "stderr": "error: Inference failed: Inference failed: Operation 'get_tensor_auto' not supported: Tensor not found with names: 'model.layers.0.mlp.gate_proj.weight', 'blk.0.ffn_gate.weight', or 'layers.0.mlp.gate_proj.weight'. Available tensors (483 total): [\"model.layers.20.mlp.c_proj.bias\", \"model.layers.26.self_attn.o_proj.bias\", \"model.layers.17.self_attn.q_proj.bias\", \"model.layers.7.mlp.c_fc.weight\", \"model.layers.10.self_attn.o_proj.bias\"], ...\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Operation 'get_tensor_auto' not supported: Tensor not found with names: 'model.layers.0.mlp.gate_proj.weight', 'blk.0.ffn_gate.weight', or 'layers.0.mlp.gate_proj.weight'. Available tensors (483 total): [\"model.layers.2.mlp.c_fc.bias\", \"model.layers.6.self_attn.o_proj.bias\", \"model.layers.24.mlp.c_fc.weight\", \"model.layers.26.input_layernorm.weight\", \"model.layers.29.post_attention_layernorm.bias\"], ...\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/safetensors/model.safetensors\n",
    "exit_code": 8,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 58256
    },
    "timestamp": "2026-02-13T15:43:53.051494094Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d8e14e155e5d",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "starcoder2-3b_run_gpu_apr_0000000000000004",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 4,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 8): [PMAT-171] Loaded embedded BPE tokenizer: 49152 vocab, 48872 merges, 1 special tokens\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[49152, 3072], expected [vocab=49152, hidden=3072]\n[APR-LOAD] Embedding dims=[49152, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0067, 0.0058, -0.0004, 0.0187, -0.0098]\n[APR-LOAD] Embedding loaded: 150994944 elements (vocab=49152 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[49152, 3072], dtype=0, expected [vocab=49152, hidden=3072]\n[APR-LOAD] LM head loaded: 150994944 elements (hidden=3072 x vocab=49152)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-DATA-QUALITY-001] Tensor 'layers.0.ffn_up_weight': DENSITY FAILURE: 100.0% zeros (max 80%)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\n[PMAT-171] Loaded embedded BPE tokenizer: 49152 vocab, 48872 merges, 1 special tokens\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[49152, 3072], expected [vocab=49152, hidden=3072]\n[APR-LOAD] Embedding dims=[49152, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0067, 0.0058, -0.0004, 0.0187, -0.0098]\n[APR-LOAD] Embedding loaded: 150994944 elements (vocab=49152 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[49152, 3072], dtype=0, expected [vocab=49152, hidden=3072]\n[APR-LOAD] LM head loaded: 150994944 elements (hidden=3072 x vocab=49152)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-DATA-QUALITY-001] Tensor 'layers.0.ffn_up_weight': DENSITY FAILURE: 100.0% zeros (max 80%)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/apr/model.apr\n",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/apr/model.apr",
    "stderr": "[PMAT-171] Loaded embedded BPE tokenizer: 49152 vocab, 48872 merges, 1 special tokens\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[49152, 3072], expected [vocab=49152, hidden=3072]\n[APR-LOAD] Embedding dims=[49152, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0067, 0.0058, -0.0004, 0.0187, -0.0098]\n[APR-LOAD] Embedding loaded: 150994944 elements (vocab=49152 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[49152, 3072], dtype=0, expected [vocab=49152, hidden=3072]\n[APR-LOAD] LM head loaded: 150994944 elements (hidden=3072 x vocab=49152)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-DATA-QUALITY-001] Tensor 'layers.0.ffn_up_weight': DENSITY FAILURE: 100.0% zeros (max 80%)\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\n[PMAT-171] Loaded embedded BPE tokenizer: 49152 vocab, 48872 merges, 1 special tokens\n[APR-LOAD] Embedding tensor 'model.embed_tokens.weight': dims=[49152, 3072], expected [vocab=49152, hidden=3072]\n[APR-LOAD] Embedding dims=[49152, 3072], using raw data (no transpose needed)\n[APR-LOAD] Token 0 embedding sample: [0.0067, 0.0058, -0.0004, 0.0187, -0.0098]\n[APR-LOAD] Embedding loaded: 150994944 elements (vocab=49152 x hidden=3072)\n[APR-LOAD] LM head tensor 'lm_head.weight': dims=[49152, 3072], dtype=0, expected [vocab=49152, hidden=3072]\n[APR-LOAD] LM head loaded: 150994944 elements (hidden=3072 x vocab=49152)\n[APR-LOAD] LM head using F32 matmul (no Q4K/Q6K found)\nerror: Inference failed: Inference failed: Format error: [F-DATA-QUALITY-001] Tensor 'layers.0.ffn_up_weight': DENSITY FAILURE: 100.0% zeros (max 80%)\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/apr/model.apr\n",
    "exit_code": 8,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 107624
    },
    "timestamp": "2026-02-13T15:45:40.676003075Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d8ecd0083a6f",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "starcoder2-3b_run_gpu_gguf_0000000000000005",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 5,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 8): error: Inference failed: Inference failed: Invalid shape: Tensor 'blk.0.ffn_up.weight' not found\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Invalid shape: Tensor 'blk.0.ffn_up.weight' not found\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/gguf/model.gguf\n",
    "output": "\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/gguf/model.gguf",
    "stderr": "error: Inference failed: Inference failed: Invalid shape: Tensor 'blk.0.ffn_up.weight' not found\n\n--- TRACE OUTPUT ---\n\u001b[36mInference tracing enabled (APR-TRACE-001)\u001b[0m\n  Trace level: basic\nerror: Inference failed: Inference failed: Invalid shape: Tensor 'blk.0.ffn_up.weight' not found\n\n--- TRACE STDOUT ---\n\u001b[1;36m=== APR Run ===\u001b[0m\n\nSource: output/workspace/bigcode/starcoder2-3b/gguf/model.gguf\n",
    "exit_code": 8,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 49424
    },
    "timestamp": "2026-02-13T15:46:30.100819845Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d8f450bb6906",
    "gate_id": "F-GOLDEN-RULE-001",
    "scenario": {
      "id": "starcoder2-3b_run_cpu_apr_0000000000000000",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Golden Rule: convert â†’ inference â†’ diff",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Golden Rule: original inference failed: error: Inference failed: Inference failed: Operation 'get_tensor_auto' not supported: Tensor not found with names: 'model.layers.0.mlp.gate_proj.weight', 'blk.0.ffn_gate.weight', or 'layers.0.mlp.gate_proj.weight'. Available tensors (483 total): [\"model.layers.27.self_attn.o_proj.weight\", \"model.layers.8.mlp.c_proj.bias\", \"model.layers.25.input_layernorm.weight\", \"model.layers.25.mlp.c_proj.bias\", \"model.layers.16.input_layernorm.bias\"], ...\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T15:47:02.324817156Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d8f80df07cfc",
    "gate_id": "F-CONTRACT-I2-001",
    "scenario": {
      "id": "starcoder2-3b_run_cpu_apr_0000000000000000",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Format contract invariant",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Corroborated",
    "reason": "I-2 Tensor Name Bijection: all 0 source tensors present in APR (0 total)",
    "output": "source=0, apr=0",
    "stderr": null,
    "exit_code": 0,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T15:47:18.384091506Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001893d9009393d019",
    "gate_id": "F-CONTRACT-I3-001",
    "scenario": {
      "id": "starcoder2-3b_run_cpu_apr_0000000000000000",
      "model": {
        "org": "bigcode",
        "name": "starcoder2-3b",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Format contract invariant",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "I-3 No Silent Fallbacks: check failed: error: Validation failed: Model self-test failed\n",
    "output": "\n\u001b[1;36m=== Model Self-Test (PMAT-112: Real Validation) ===\u001b[0m\nModel: \u001b[36moutput/workspace/bigcode/starcoder2-3b/apr/model.apr\u001b[0m\n\nâ”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”\nâ”‚  #  â”‚      Component      â”‚               Details                â”‚ Pass â”‚\nâ”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 1   â”‚ Tokenizer           â”‚ tokens=[1, 2]                        â”‚ \u001b[31mâŒ   \u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 2   â”‚ Embedding           â”‚ Found embedding tensor               â”‚ \u001b[32mâœ…   \u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 3   â”‚ Positional Encoding â”‚ RoPE computed inline                 â”‚ \u001b[32mâœ…   \u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 4   â”‚ Q/K/V Projection    â”‚ Q/K/V found                          â”‚ \u001b[32mâœ…   \u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 5   â”‚ Attention Scores    â”‚ Attention output found               â”‚ \u001b[32mâœ…   \u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 6   â”‚ Feed-Forward (MLP)  â”‚ Missing MLP                          â”‚ \u001b[31mâŒ   \u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 7   â”‚ Layer Norm          â”‚ 30 layers                            â”‚ \u001b[32mâœ…   \u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 8   â”‚ LM Head             â”‚ vocab_size=49152                     â”‚ \u001b[32mâœ…   \u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 9   â”‚ Logits â†’ Probs      â”‚ Forward failed: Format error: No ... â”‚ \u001b[31mâŒ   \u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 10  â”‚ Sampler/Decode      â”‚ Forward failed: Format error: No ... â”‚ \u001b[31mâŒ   \u001b[0m â”‚\nâ””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜\n\n\u001b[1;31mâŒ 6/10 STAGES PASSED. CHECK STAGE LOGS.\u001b[0m\n",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-13T15:47:54.985903267Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  }
]