[
  {
    "id": "00000000000000001890ca8d013e9305",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 6
    },
    "timestamp": "2026-02-03T16:49:20.516687028Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d0192efd6",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_apr_0000000000000001",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 1,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 5
    },
    "timestamp": "2026-02-03T16:49:20.522216084Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d01e8eb3a",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_gguf_0000000000000002",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 2,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 5
    },
    "timestamp": "2026-02-03T16:49:20.527847584Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d0233d077",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_safetensors_0000000000000003",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 3,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 4
    },
    "timestamp": "2026-02-03T16:49:20.532759008Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d0280f1ef",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_apr_0000000000000004",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 4,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 5
    },
    "timestamp": "2026-02-03T16:49:20.537811945Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d02db3c15",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_gguf_0000000000000005",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 5,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 5
    },
    "timestamp": "2026-02-03T16:49:20.543731270Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d032e8052",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_chat_cpu_safetensors_0000000000000006",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "chat",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 6,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 5
    },
    "timestamp": "2026-02-03T16:49:20.549186284Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d0379f1bb",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_chat_cpu_apr_0000000000000007",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "chat",
      "backend": "cpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 7,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 4
    },
    "timestamp": "2026-02-03T16:49:20.554131148Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d03c4f875",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_chat_cpu_gguf_0000000000000008",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "chat",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 8,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 4
    },
    "timestamp": "2026-02-03T16:49:20.559046898Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d040d8aee",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_chat_gpu_safetensors_0000000000000009",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "chat",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 9,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 4
    },
    "timestamp": "2026-02-03T16:49:20.563801866Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d04575978",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_chat_gpu_apr_000000000000000a",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "chat",
      "backend": "gpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 10,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 4
    },
    "timestamp": "2026-02-03T16:49:20.568639949Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d04aaac6a",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_chat_gpu_gguf_000000000000000b",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "chat",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 11,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 5
    },
    "timestamp": "2026-02-03T16:49:20.574099930Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d04f326f2",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_serve_cpu_safetensors_000000000000000c",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "serve",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 12,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 4
    },
    "timestamp": "2026-02-03T16:49:20.578852735Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d054a77fc",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_serve_cpu_apr_000000000000000d",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "serve",
      "backend": "cpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 13,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 5
    },
    "timestamp": "2026-02-03T16:49:20.584574932Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d05a2d14a",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_serve_cpu_gguf_000000000000000e",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "serve",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 14,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 5
    },
    "timestamp": "2026-02-03T16:49:20.590362288Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d05fcbc0f",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_serve_gpu_safetensors_000000000000000f",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "serve",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 15,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/safetensors/model.safetensors\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 5
    },
    "timestamp": "2026-02-03T16:49:20.596257807Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d065378d3",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_serve_gpu_apr_0000000000000010",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "serve",
      "backend": "gpu",
      "format": "apr",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 16,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/apr/model.apr\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 5
    },
    "timestamp": "2026-02-03T16:49:20.601940214Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d06988fe0",
    "gate_id": "G2-BASIC",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_serve_gpu_gguf_0000000000000011",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "serve",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "What is 2+2?",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 17,
      "trace_level": "none",
      "oracle_type": "arithmetic"
    },
    "outcome": "Falsified",
    "reason": "Command failed (exit 3): error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n",
    "output": "Source: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf",
    "stderr": "error: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE OUTPUT ---\nInference tracing enabled (APR-TRACE-001)\n  Trace level: basic\nerror: File not found: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n\n--- TRACE STDOUT ---\n=== APR Run ===\n\nSource: /home/noah/.cache/apr-models/qwen2-5-coder-32b-instruct/gguf/model.gguf\n",
    "exit_code": 3,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 4
    },
    "timestamp": "2026-02-03T16:49:20.606467558Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d06bc2eb8",
    "gate_id": "F-CONV-G-A",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Convert Gguf to Apr",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Conversion infrastructure error: Execution error: Inference failed: error: Inference failed: Inference failed: Security error: Invalid model file extension: '.'. Expected one of: gguf, safetensors, apr, bin\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.608801081Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d06df3e60",
    "gate_id": "F-CONV-G-A",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "apr",
      "prompt": "Convert Gguf to Apr",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Conversion infrastructure error: Execution error: Inference failed: error: Inference failed: Inference failed: Security error: Invalid model file extension: '.'. Expected one of: gguf, safetensors, apr, bin\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.611098649Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d06ff2781",
    "gate_id": "F-CONV-A-G",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_gguf_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "Convert Apr to Gguf",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Conversion infrastructure error: Execution error: Inference failed: error: Inference failed: Inference failed: Security error: Invalid model file extension: '.'. Expected one of: gguf, safetensors, apr, bin\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.613189835Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d072065a7",
    "gate_id": "F-CONV-A-G",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_gguf_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "Convert Apr to Gguf",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Conversion infrastructure error: Execution error: Inference failed: error: Inference failed: Inference failed: Security error: Invalid model file extension: '.'. Expected one of: gguf, safetensors, apr, bin\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.615368524Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d074aac65",
    "gate_id": "F-CONV-G-S",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "Convert Gguf to SafeTensors",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Conversion infrastructure error: Execution error: Inference failed: error: Inference failed: Inference failed: Security error: Invalid model file extension: '.'. Expected one of: gguf, safetensors, apr, bin\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.618141950Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d0779f9b1",
    "gate_id": "F-CONV-G-S",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "Convert Gguf to SafeTensors",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Conversion infrastructure error: Execution error: Inference failed: error: Inference failed: Inference failed: Security error: Invalid model file extension: '.'. Expected one of: gguf, safetensors, apr, bin\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.621242020Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d07a30c5a",
    "gate_id": "F-CONV-S-G",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_gguf_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "Convert SafeTensors to Gguf",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Conversion infrastructure error: Execution error: Inference failed: error: Inference failed: Inference failed: Security error: Invalid model file extension: '.'. Expected one of: gguf, safetensors, apr, bin\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.623930969Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d07c8ee9f",
    "gate_id": "F-CONV-S-G",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_gguf_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "Convert SafeTensors to Gguf",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Conversion infrastructure error: Execution error: Inference failed: error: Inference failed: Inference failed: Security error: Invalid model file extension: '.'. Expected one of: gguf, safetensors, apr, bin\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.626413546Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d07f042de",
    "gate_id": "F-CONV-A-S",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "Convert Apr to SafeTensors",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Conversion infrastructure error: Execution error: Inference failed: error: Inference failed: Inference failed: Security error: Invalid model file extension: '.'. Expected one of: gguf, safetensors, apr, bin\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.628994081Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d081dfdb8",
    "gate_id": "F-CONV-A-S",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "Convert Apr to SafeTensors",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Conversion infrastructure error: Execution error: Inference failed: error: Inference failed: Inference failed: Security error: Invalid model file extension: '.'. Expected one of: gguf, safetensors, apr, bin\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.631988781Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d08423768",
    "gate_id": "F-CONV-S-A",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Convert SafeTensors to Apr",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Conversion infrastructure error: Execution error: Inference failed: error: Inference failed: Inference failed: Security error: Invalid model file extension: '.'. Expected one of: gguf, safetensors, apr, bin\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.634362755Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d086d2958",
    "gate_id": "F-CONV-S-A",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "apr",
      "prompt": "Convert SafeTensors to Apr",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Conversion infrastructure error: Execution error: Inference failed: error: Inference failed: Inference failed: Security error: Invalid model file extension: '.'. Expected one of: gguf, safetensors, apr, bin\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.637177804Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d08c59671",
    "gate_id": "F-CONV-RT-001",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_gguf_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "gguf",
      "prompt": "Round-trip conversion",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Round-trip failed: Execution error: Conversion failed: error: Validation failed: Source inspection failed: Invalid model format: No file extension found\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.642972101Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d090ed7fc",
    "gate_id": "F-CONV-RT-001",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_gguf_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "gguf",
      "prompt": "Round-trip conversion",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Round-trip failed: Execution error: Conversion failed: error: Validation failed: Source inspection failed: Invalid model format: No file extension found\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.647773248Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d095b740d",
    "gate_id": "F-CONV-RT-002",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "Multi-hop: SafeTensorsAprGgufSafeTensors",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Multi-hop chain failed: Execution error: Conversion failed: error: Validation failed: Source inspection failed: Invalid model format: No file extension found\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.652793906Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d09a155d4",
    "gate_id": "F-CONV-RT-002",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "Multi-hop: SafeTensorsAprGgufSafeTensors",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Multi-hop chain failed: Execution error: Conversion failed: error: Validation failed: Source inspection failed: Invalid model format: No file extension found\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.657373739Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d0a05f4a1",
    "gate_id": "F-CONV-RT-003",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "safetensors",
      "prompt": "Multi-hop: SafeTensorsAprGgufAprSafeTensors",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Multi-hop chain failed: Execution error: Conversion failed: error: Validation failed: Source inspection failed: Invalid model format: No file extension found\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.663970206Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d0a5fe237",
    "gate_id": "F-CONV-RT-003",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_safetensors_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "safetensors",
      "prompt": "Multi-hop: SafeTensorsAprGgufAprSafeTensors",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Multi-hop chain failed: Execution error: Conversion failed: error: Validation failed: Source inspection failed: Invalid model format: No file extension found\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.669861990Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d0a872947",
    "gate_id": "F-CONV-IDEM-001",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Idempotency: GGUFAPR twice",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Idempotency test failed: Execution error: Conversion failed: error: Validation failed: Source inspection failed: Invalid model format: No file extension found\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.672437497Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d0aaad992",
    "gate_id": "F-CONV-IDEM-001",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "apr",
      "prompt": "Idempotency: GGUFAPR twice",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Idempotency test failed: Execution error: Conversion failed: error: Validation failed: Source inspection failed: Invalid model format: No file extension found\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.674774075Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d0ad7cfdf",
    "gate_id": "F-CONV-COM-001",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Commutativity: GGUFAPR vs GGUFSTAPR",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Commutativity test failed: Execution error: Conversion failed: error: Validation failed: Source inspection failed: Invalid model format: No file extension found\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.677721464Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d0aff88e5",
    "gate_id": "F-CONV-COM-001",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_gpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "gpu",
      "format": "apr",
      "prompt": "Commutativity: GGUFAPR vs GGUFSTAPR",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Commutativity test failed: Execution error: Conversion failed: error: Validation failed: Source inspection failed: Invalid model format: No file extension found\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.680323962Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  },
  {
    "id": "00000000000000001890ca8d0b244acd",
    "gate_id": "F-GOLDEN-RULE-001",
    "scenario": {
      "id": "Qwen2.5-Coder-32B-Instruct_run_cpu_apr_0000000000000000",
      "model": {
        "org": "Qwen",
        "name": "Qwen2.5-Coder-32B-Instruct",
        "variant": null
      },
      "modality": "run",
      "backend": "cpu",
      "format": "apr",
      "prompt": "Golden Rule: convert  inference  diff",
      "temperature": 0.0,
      "max_tokens": 32,
      "seed": 0,
      "trace_level": "none",
      "oracle_type": "garbage"
    },
    "outcome": "Falsified",
    "reason": "Golden Rule: original inference failed: error: Inference failed: Inference failed: Security error: Invalid model file extension: '.'. Expected one of: gguf, safetensors, apr, bin\n",
    "output": "N/A",
    "stderr": null,
    "exit_code": null,
    "metrics": {
      "tokens_per_second": null,
      "time_to_first_token_ms": null,
      "total_tokens": null,
      "memory_peak_mb": null,
      "duration_ms": 0
    },
    "timestamp": "2026-02-03T16:49:20.682733559Z",
    "host": {
      "hostname": "noah-Lambda-Vector",
      "os": "linux",
      "cpu": "unknown",
      "gpu": null,
      "apr_version": "unknown"
    },
    "metadata": {}
  }
]