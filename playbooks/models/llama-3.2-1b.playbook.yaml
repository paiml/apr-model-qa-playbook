# Llama 3.2 1B Model Qualification Playbook
# Model: meta-llama/Llama-3.2-1B-Instruct
# Generated: 2026-01-30
# MQS Target: 85+

name: llama-3.2-1b
version: "1.0.0"
description: "Qualification playbook for Llama-3.2-1B-Instruct"

model:
  hf_repo: "meta-llama/Llama-3.2-1B-Instruct"
  formats:
    - gguf
    - safetensors
    - apr
  quantizations:
    - q4_k_m
    - q5_k_m
    - q8_0
  size_category: small

test_matrix:
  modalities:
    - run
    - chat
    - serve
  backends:
    - cpu
    - gpu
  scenario_count: 100
  seed: 42
  timeout_ms: 60000

gates:
  g1_model_loads: true
  g2_basic_inference: true
  g3_no_crashes: true
  g4_output_quality: true

oracles:
  - type: arithmetic
    config:
      tolerance: 0.01
  - type: garbage
    config:
      max_repetition_ratio: 0.3
      min_unique_chars: 10
  - type: code_syntax
    config:
      languages:
        - python
        - rust
        - javascript
  - type: response
    config:
      min_relevance: 0.3

failure_policy: stop_on_p0

property_tests:
  enabled: true
  cases: 100
  max_shrink_iters: 1000

metadata:
  author: "apr-qa-gen"
  architecture: "llama"
  expected_mqs: 85
  tags:
    - general
    - instruct
    - small
