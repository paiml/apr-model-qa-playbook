# Qwen2.5-Coder-0.5B MVP Playbook
# Full surface coverage: 3 formats × 2 backends × 3 modalities = 18 tests
name: qwen2.5-coder-0.5b-mvp
version: "1.0.0"
description: "MVP certification for Qwen2.5-Coder-0.5B-Instruct"

model:
  hf_repo: "Qwen/Qwen2.5-Coder-0.5B-Instruct"
  formats:
    - safetensors  # Ground truth (HuggingFace source)
    - apr          # APR native format
    - gguf         # Third-party format
  quantizations:
    - q4_k_m
  size_category: tiny

test_matrix:
  modalities:
    - run
    - chat
    - serve
  backends:
    - cpu
    - gpu
  scenario_count: 1
  seed: 42
  timeout_ms: 60000

gates:
  g1_model_loads: true
  g2_basic_inference: true
  g3_no_crashes: true
  g4_output_quality: true

oracles:
  - type: arithmetic
    config:
      tolerance: 0.01
  - type: garbage
    config:
      max_repetition_ratio: 0.3
      min_unique_chars: 10

failure_policy: collect_all

# 6-column profiling: 3 formats × 2 backends
profile_ci:
  enabled: true
  warmup: 1
  measure: 2
  formats: [safetensors, apr, gguf]  # safetensors = ground truth
  backends: [cpu, gpu]
  assertions:
    min_throughput_cpu: 5.0    # tok/s (CPU baseline)
    min_throughput_gpu: 50.0   # tok/s (GPU should be faster)

# Format contract invariant tests (GH-190/191 Five-Whys)
contract_tests:
  invariants: ["I-2", "I-3", "I-4", "I-5"]

metadata:
  author: "apr-qa-gen"
  tier: "mvp"
  architecture: "qwen2"
  tags:
    - code
    - instruct
    - mvp
